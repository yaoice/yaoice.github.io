<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="爱折腾的工程师">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://www.iceyao.com.cn//img/post-bg-unix-linux.jpg">
    <meta property="twitter:image" content="https://www.iceyao.com.cn//img/post-bg-unix-linux.jpg" />
    

    
    <meta name="title" content="AI Agent学习笔记" />
    <meta property="og:title" content="AI Agent学习笔记" />
    <meta property="twitter:title" content="AI Agent学习笔记" />
    

    
    <meta name="description" content="AI Agent学习笔记">
    <meta property="og:description" content="AI Agent学习笔记" />
    <meta property="twitter:description" content="AI Agent学习笔记" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="iceyao, IceYao&#39;s Blog, 博客, 个人网站, 互联网, Web, 云原生, PaaS, Istio, Kubernetes, 微服务, Microservice">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>AI Agent学习笔记 | 爱折腾的工程师 | IceYao&#39;s Blog</title>

    <link rel="canonical" href="/2024/03/30/ai-agent-readnotes/">

    
    
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hugo-theme-cleanwhite.min.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">

    
    <link rel="stylesheet" href="/css/font-awesome.all.min.css">

    
    

    
    <script src="/js/jquery.min.js"></script>

    
    <script src="/js/bootstrap.min.js"></script>

    
    <script src="/js/hux-blog.min.js"></script>

    
    <script src="/js/lazysizes.min.js"></script>

    
    

</head>



  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-9J7CKFVPPM"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-9J7CKFVPPM');
        }
      </script>
    
  







<nav class="navbar navbar-default navbar-custom navbar-fixed-top">

    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">爱折腾的工程师</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">All Posts</a>
                    </li>
                    
                        
                    
                    
		    
                        <li><a href="/archive//">ARCHIVE</a></li>
                    
                        <li><a href="/notes//">NOTES</a></li>
                    
                        <li><a href="/about//">ABOUT</a></li>
                    
		            <li>
                        <a href="/search"><i class="fa fa-search"></i></a>
		           </li>
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/post-bg-unix-linux.jpg')
    }
</style>

<header class="intro-header" >

    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/llm" title="LLM">
                            LLM
                        </a>
                        
                    </div>
                    <h1>AI Agent学习笔记</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        
                            Posted by 
                            
                                iceyao
                             
                            on 
                            Saturday, March 30, 2024
                            
                            
                            
                            
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                <h1 id="ai-agent核心思想---llm提示推理策略">AI Agent核心思想 - LLM提示推理策略</h1>
<h2 id="react提示工程">ReAct提示工程</h2>
<p>ReAct提示工程是一种用于提升大型语言模型（LLMs）性能的先进技术，它模仿人类在现实世界中的思考和行动方式。这种方法通过结合口头推理和实际行动来获取信息，从而提高模型在处理复杂任务时的准确性和可靠性。ReAct的核心思想是让LLM在执行任务时，不仅展示其内部的推理过程（即&quot;思考&quot;），还要模拟实际的&quot;行动&quot;，比如搜索信息或与环境互动，以此来增强其解决问题的能力</p>
<h2 id="reflectionself-critique">Reflection/Self-Critique</h2>
<p>Reflection(自我反思)是一种在人工智能领域中用于增强大型语言模型（LLMs）性能的技术。它通过模拟人类的自我反思过程，使得模型能够在执行任务时更加深入地理解问题，并生成更加准确和连贯的输出。这一概念源自于Shinn et al. (2023)的研究，他们提出了一种将策略参数化为智能体的记忆编码与LLM的参数选择配对的方法.</p>
<p>通过自我反思，大型语言模型不仅能够生成响应，还能够在生成的过程中模拟人类的思考过程，从而提高输出的质量和可靠性。这种方法特别适用于需要模型进行深度思考和创新的场景，如编写代码、生成新知识或解决复杂问题等。通过自我反思，模型能够更好地理解任务需求，避免常见的错误，并提高其解决问题的能力。</p>
<h1 id="ai-agent框架">AI Agent框架</h1>
<p>热门AI Agent开发框架对比：</p>
<table>
<thead>
<tr>
<th>框架名称</th>
<th>简介</th>
<th>License</th>
<th>GitHub Stars</th>
<th>所属公司/组织</th>
<th>开发语言</th>
<th>社区活跃度</th>
<th>Github链接</th>
</tr>
</thead>
<tbody>
<tr>
<td>AutoGPT</td>
<td>基于GPT 3.5/4的自动化生成框架，能够独立完成多目标复杂任务</td>
<td>MIT</td>
<td>160k</td>
<td>个人Significant Gravitas</td>
<td>JS/Python</td>
<td>discord 52132名成员加入</td>
<td><a href="https://github.com/Significant-Gravitas/AutoGPT">https://github.com/Significant-Gravitas/AutoGPT</a></td>
</tr>
<tr>
<td>AutoGen</td>
<td>微软开源的多智能体应用开发框架，支持LLM工作流构建</td>
<td>CC-BY-4.0, MIT</td>
<td>23.5k</td>
<td>微软</td>
<td>Python</td>
<td>discord 15561名成员</td>
<td><a href="https://github.com/microsoft/autogen">https://github.com/microsoft/autogen</a></td>
</tr>
<tr>
<td>MetaGPT</td>
<td>中国团队开发的多智能体框架，应用于软件开发等场景</td>
<td>MIT</td>
<td>37.5k</td>
<td>DeepWisdom</td>
<td>Python</td>
<td>discord 4404名成员</td>
<td><a href="https://github.com/geekan/MetaGPT">https://github.com/geekan/MetaGPT</a></td>
</tr>
<tr>
<td>AgentGPT</td>
<td>任务驱动的自主AI代理，在浏览器配置，有依赖langchain</td>
<td>GPL-3.0</td>
<td>29.3k</td>
<td>Reworkd AI</td>
<td>TS/Python</td>
<td>discord 25419名成员</td>
<td><a href="https://github.com/reworkd/AgentGPT">https://github.com/reworkd/AgentGPT</a></td>
</tr>
<tr>
<td>ChatDev</td>
<td>通过各种不同角色的智能体运营，包括执行官，产品官，技术官，程序员 ，审查员，测试员，设计师等</td>
<td>Apache-2.0</td>
<td>21.4k</td>
<td>面壁智能</td>
<td>Python</td>
<td>discord 1589名成员</td>
<td><a href="https://github.com/OpenBMB/ChatDev">https://github.com/OpenBMB/ChatDev</a></td>
</tr>
<tr>
<td>crewAI</td>
<td>适用本地大模型AI自动化协作框架，基于langchain之上</td>
<td>MIT</td>
<td>10.6k</td>
<td>OpenAI开发</td>
<td>Python</td>
<td>discord 4332名成员</td>
<td><a href="https://github.com/joaomdmoura/crewAI">https://github.com/joaomdmoura/crewAI</a></td>
</tr>
<tr>
<td>LangChain</td>
<td>专注于通用NLP任务的框架，支持与外部知识库的集成</td>
<td>MIT</td>
<td>80.2k</td>
<td>LangChain</td>
<td>Python</td>
<td>discord 39654名成员</td>
<td><a href="https://github.com/langchain-ai/langchain">https://github.com/langchain-ai/langchain</a></td>
</tr>
</tbody>
</table>
<h1 id="autogpt">AutoGPT</h1>
<p>基于GPT 3.5/4的自动化生成框架，能够独立完成多目标复杂任务</p>
<h2 id="quickstart">QuickStart</h2>
<p>按照官方提供的QuickStart指引快速在本地起个demo：<a href="https://github.com/Significant-Gravitas/AutoGPT/blob/master/QUICKSTART.md">https://github.com/Significant-Gravitas/AutoGPT/blob/master/QUICKSTART.md</a></p>
<p>如果遇到poetry软链接不支持问题，需要改下setup.sh脚本中安装poetry的部分. poetry是不会负责Python版本的管理.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># vim setup.sh</span>
</span></span><span style="display:flex;"><span>curl -sSL https://install.python-poetry.org | sed <span style="color:#f1fa8c">&#39;s/symlinks=False/symlinks=True/&#39;</span> | python3 -
</span></span></code></pre></div><p>AutoGPT官方不支持对接本地大模型，github有个讨论支持本地大模型的issue：<a href="https://github.com/Significant-Gravitas/AutoGPT/issues/25">https://github.com/Significant-Gravitas/AutoGPT/issues/25</a>，项目维护者在帖子上答复即将实现这个功能。</p>
<h2 id="核心组件">核心组件</h2>
<ul>
<li>Agent：理解为开发一个叫AutoGPT的Agent</li>
<li>Benchmark：提供<code>agbenchmark</code>工具对开发的agent进行测试评分</li>
<li>Forge：提供一些现成的模版用于Agent开发</li>
<li>Frontend：简易使用、开源的前端UI，适用于任何兼容Agent协议的Agent</li>
</ul>
<p>Agent协议：用于统一agents开发的一套准则，来自AI-Engineer-Foundation提出的<a href="https://github.com/AI-Engineer-Foundation/agent-protocol">Agent Protocol</a>，AutoGPT就是采用Agent protocol来开发Agent.</p>
<p>AutoGPT在构建agent的生态，包括benchmark和protocol</p>
<h2 id="部署">部署</h2>
<p>提前设置好.condarc，用命令<code>conda config --show-sources</code>校验</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># vim ~/.condarc</span>
</span></span><span style="display:flex;"><span>channels:
</span></span><span style="display:flex;"><span>   - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
</span></span><span style="display:flex;"><span>   - defaults
</span></span><span style="display:flex;"><span>show_channel_urls: <span style="color:#8be9fd;font-style:italic">true</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ssl_verify: <span style="color:#8be9fd;font-style:italic">false</span>
</span></span></code></pre></div><p>1.使用conda创建一个虚拟环境</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>conda create --name autogpt <span style="color:#8be9fd;font-style:italic">python</span><span style="color:#ff79c6">=</span>3.10
</span></span><span style="display:flex;"><span>conda activate autogpt
</span></span></code></pre></div><p>2.安装poetry</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip3 install poetry
</span></span></code></pre></div><p>3.克隆autogpt仓库</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/Significant-Gravitas/AutoGPT.git
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">cd</span> autogpts/autogpt
</span></span></code></pre></div><p>4.配置环境变量</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cp .env.template .env
</span></span><span style="display:flex;"><span>vim .env
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">OPENAI_API_KEY</span><span style="color:#ff79c6">=</span>sk-qwertykeys123456  <span style="color:#6272a4"># 替换为实际的API KEY</span>
</span></span></code></pre></div><p>5.安装依赖</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>poetry install
</span></span></code></pre></div><p>6.运行AutoGPT，提供两种交互方式，一种是过时的命令行方式；另一种是Agent协议模式下的webUI方式。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># 命令行方式</span>
</span></span><span style="display:flex;"><span>./autogpt.sh run
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># webUI方式</span>
</span></span><span style="display:flex;"><span>./autogpt.sh serve
</span></span></code></pre></div><p>默认输出产出在./data/agents目录下</p>
<h2 id="测试验证">测试验证</h2>
<p>例如提个任务：使用golang编写监控虚拟机磁盘的功能</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#ff79c6">(</span>autogpt<span style="color:#ff79c6">)</span> iceyao$ ./autogpt.sh run
</span></span><span style="display:flex;"><span>Missing packages:
</span></span><span style="display:flex;"><span>auto-gpt-plugin-template <span style="color:#ff79c6">(</span>*<span style="color:#ff79c6">)</span> @ git+https://github.com/Significant-Gravitas/Auto-GPT-Plugin-Template@0.1.0, autogpt-forge <span style="color:#ff79c6">(</span>*<span style="color:#ff79c6">)</span> @ git+https://github.com/Significant-Gravitas/AutoGPT.git@ab05b7ae70754c063909#subdirectory<span style="color:#ff79c6">=</span>autogpts/forge, beautifulsoup4 <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>4.12.2,&lt;5.0.0<span style="color:#ff79c6">)</span>, boto3 <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>1.33.6,&lt;2.0.0<span style="color:#ff79c6">)</span>, colorama <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>0.4.6,&lt;0.5.0<span style="color:#ff79c6">)</span>, demjson3 <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>3.0.0,&lt;4.0.0<span style="color:#ff79c6">)</span>, distro <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>1.8.0,&lt;2.0.0<span style="color:#ff79c6">)</span>, docker, duckduckgo-search <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>5.0.0,&lt;6.0.0<span style="color:#ff79c6">)</span>, en-core-web-sm <span style="color:#ff79c6">(</span>*<span style="color:#ff79c6">)</span> @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl, fastapi <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>0.109.1,&lt;0.110.0<span style="color:#ff79c6">)</span>, ftfy <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>6.1.1,&lt;7.0.0<span style="color:#ff79c6">)</span>, gitpython <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>3.1.32,&lt;4.0.0<span style="color:#ff79c6">)</span>, google-api-python-client, gTTS <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>2.3.1,&lt;3.0.0<span style="color:#ff79c6">)</span>, hypercorn <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>0.14.4,&lt;0.15.0<span style="color:#ff79c6">)</span>, inflection, jsonschema, numpy, openai <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>1.7.2,&lt;2.0.0<span style="color:#ff79c6">)</span>, orjson <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>3.8.10,&lt;4.0.0<span style="color:#ff79c6">)</span>, Pillow, pinecone-client <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>2.2.1,&lt;3.0.0<span style="color:#ff79c6">)</span>, playsound <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>1.2.2,&lt;1.3.0<span style="color:#ff79c6">)</span>, pydantic, pylatexenc, pypdf <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>3.1.0,&lt;4.0.0<span style="color:#ff79c6">)</span>, python-docx, python-dotenv <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>1.0.0,&lt;2.0.0<span style="color:#ff79c6">)</span>, pyyaml <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>6.0,&lt;7.0<span style="color:#ff79c6">)</span>, readability-lxml <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>0.8.1,&lt;0.9.0<span style="color:#ff79c6">)</span>, redis, selenium <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>4.11.2,&lt;5.0.0<span style="color:#ff79c6">)</span>, sentry-sdk <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>1.40.4,&lt;2.0.0<span style="color:#ff79c6">)</span>, spacy <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>3.0.0,&lt;4.0.0<span style="color:#ff79c6">)</span>, tenacity <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>8.2.2,&lt;9.0.0<span style="color:#ff79c6">)</span>, tiktoken <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>0.5.0,&lt;0.6.0<span style="color:#ff79c6">)</span>, webdriver-manager, openapi-python-client <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>0.14.0,&lt;0.15.0<span style="color:#ff79c6">)</span>, google-cloud-logging <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>3.8.0,&lt;4.0.0<span style="color:#ff79c6">)</span>, google-cloud-storage <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>2.13.0,&lt;3.0.0<span style="color:#ff79c6">)</span>, psycopg2-binary <span style="color:#ff79c6">(</span>&gt;<span style="color:#ff79c6">=</span>2.9.9,&lt;3.0.0<span style="color:#ff79c6">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Installing dependencies from lock file
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>No dependencies to install or update
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Installing the current project: agpt <span style="color:#ff79c6">(</span>0.5.0<span style="color:#ff79c6">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Finished installing packages! Starting AutoGPT...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,144 INFO  HTTP Request: GET https://api.openai.com/v1/models <span style="color:#f1fa8c">&#34;HTTP/1.1 200 OK&#34;</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,865 INFO  NEWS: Welcome to AutoGPT!
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,866 INFO  NEWS: Below you<span style="color:#f1fa8c">&#39;ll find the latest AutoGPT News and feature updates!
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:53:42,866 INFO  NEWS: If you don&#39;</span>t wish to see this message, you can run AutoGPT with the --skip-news flag.
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,867 INFO  NEWS:
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,867 INFO  NEWS: QUICK LINKS 🔗
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,867 INFO  NEWS: --------------
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,867 INFO  NEWS: 🌎 Official Website: https://agpt.co.
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,868 INFO  NEWS: 📖 User Guide: https://docs.agpt.co/autogpt.
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,868 INFO  NEWS: 👩 Contributors Wiki: https://github.com/Significant-Gravitas/Nexus/wiki/Contributing.
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,868 INFO  NEWS:
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,868 INFO  NEWS: v0.5.0 RELEASE HIGHLIGHTS! 🚀🚀
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,868 INFO  NEWS: -------------------------------
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,869 INFO  NEWS: Cloud-readiness, a new UI, support <span style="color:#ff79c6">for</span> the newest Agent Protocol version, and much more:
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,869 INFO  NEWS: v0.5.0 is our biggest release yet!
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,869 INFO  NEWS:
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,869 INFO  NEWS: Take a look at the Release Notes on Github <span style="color:#ff79c6">for</span> the full changelog:
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,869 INFO  NEWS: https://github.com/Significant-Gravitas/AutoGPT/releases.
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,870 INFO  NEWS:
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,871 INFO  Smart LLM: gpt-4-turbo-preview
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,872 INFO  Fast LLM: gpt-3.5-turbo-0125
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,872 INFO  Browser: chrome
</span></span><span style="display:flex;"><span>2024-04-07 14:53:42,874 INFO  Code Execution: DISABLED <span style="color:#ff79c6">(</span>Docker unavailable<span style="color:#ff79c6">)</span>
</span></span><span style="display:flex;"><span>Enter the task that you want AutoGPT to execute, with as much detail as possible: Enter the task that you want AutoGPT to execute, with as much detail as possible: 编
</span></span><span style="display:flex;"><span>Enter the task that you want AutoGPT to execute, with as much detail as possible: 使用golang编写监控虚拟机磁盘的功能
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,471 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions <span style="color:#f1fa8c">&#34;HTTP/1.1 200 OK&#34;</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,479 INFO  Current AI Settings:
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,480 INFO  -------------------:
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,480 INFO  Name : GoVMDiskMonitorGPT
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,480 INFO  Role : a specialized agent designed to monitor virtual machine disk usage using Go programming, ensuring efficient disk space management and preventing potential storage issues.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,480 INFO  Constraints:
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,480 INFO  - Exclusively use the commands listed below.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,480 INFO  - You can only act proactively, and are unable to start background <span style="color:#8be9fd;font-style:italic">jobs</span> or <span style="color:#8be9fd;font-style:italic">set</span> up webhooks <span style="color:#ff79c6">for</span> yourself. Take this into account when planning your actions.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,481 INFO  - You are unable to interact with physical objects. If this is absolutely necessary to fulfill a task or objective or to <span style="color:#8be9fd;font-style:italic">complete</span> a step, you must ask the user to <span style="color:#ff79c6">do</span> it <span style="color:#ff79c6">for</span> you. If the user refuses this, and there is no other way to achieve your goals, you must terminate to avoid wasting <span style="color:#8be9fd;font-style:italic">time</span> and energy.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,481 INFO  - Do not access or modify user data stored on the virtual machine disks without explicit permission.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,481 INFO  - Ensure the monitoring tool respects the privacy and security settings of the virtual machines it is monitoring.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,481 INFO  - Limit the impact on virtual machine performance by optimizing the monitoring tool<span style="color:#f1fa8c">&#39;s resource usage.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,504 INFO  - Do not store sensitive information in plaintext within the application code or logs.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,505 INFO  - Ensure compliance with relevant data protection and privacy laws.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,505 INFO  Resources:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,505 INFO  - Internet access for searches and information gathering.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,505 INFO  - The ability to read and write files.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,505 INFO  - You are a Large Language Model, trained on millions of pages of text, including a lot of factual knowledge. Make use of this factual knowledge to avoid unnecessary gathering of information.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,505 INFO  Best practices:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,506 INFO  - Continuously review and analyze your actions to ensure you are performing to the best of your abilities.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,506 INFO  - Constructively self-criticize your big-picture behavior constantly.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,506 INFO  - Reflect on past decisions and strategies to refine your approach.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,506 INFO  - Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,506 INFO  - Only make use of your information gathering abilities to find information that you don&#39;</span>t yet have knowledge of.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,506 INFO  - Periodically check the disk usage on virtual machines to identify potential storage issues before they become critical.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,506 INFO  - Implement logging mechanisms to keep a historical record of disk space usage trends over time.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:34,507 INFO  - Use Go<span style="color:#f1fa8c">&#39;s concurrency features to monitor multiple virtual machines efficiently.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,507 INFO  - Notify administrators via email or another preferred communication channel when disk space usage exceeds a predefined threshold.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:34,507 INFO  - Provide clear documentation and comments within the code to ensure easy maintenance and scalability.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Continue with these settings? [Y/n] 2024-04-07 14:54:34,757 INFO  NOTE: All files/directories created by this agent can be found inside its workspace at: /Users/iceyao/Desktop/AutoGPT/autogpts/autogpt/data/agents/GoVMDiskMonitorGPT-07d8f7e6/workspace
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">| Thinking...
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:43,379 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions &#34;HTTP/1.1 200 OK&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:43,761 INFO  GOVMDISKMONITORGPT THOUGHTS: The initial step in developing this feature is to understand the requirements and the environment in which the monitoring tool will operate.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:43,762 INFO  REASONING: Developing such a tool requires knowledge of the APIs or libraries available in Go for accessing disk usage information. Given the constraints, I must use my base knowledge without executing code or directly accessing Go libraries.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:43,762 INFO  PLAN:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:43,762 INFO  -  Ask the user for details regarding the virtual machine environment and operating systems.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:43,763 INFO  -  Research Go libraries or standard library packages that could be used for disk monitoring.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:43,763 INFO  -  Structure a basic outline of the monitoring tool, including key functions and concurrency.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:54:43,763 INFO  -  Consider how to respect privacy and optimize performance in the tool&#39;</span>s design.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:43,763 INFO  -  Plan <span style="color:#ff79c6">for</span> user notifications and logging of disk usage trends.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:43,764 INFO  CRITICISM: I immediately considered technical details without first clarifying the scope of the virtual machine environment <span style="color:#ff79c6">(</span>e.g., VMWare, VirtualBox<span style="color:#ff79c6">)</span> and the specific operating system<span style="color:#ff79c6">(</span>s<span style="color:#ff79c6">)</span> the virtual machines will be running. This information could impact the approach and available libraries.
</span></span><span style="display:flex;"><span>2024-04-07 14:54:43,764 INFO  SPEAK: Could you please specify the virtual machine environment <span style="color:#ff79c6">(</span>e.g., VMWare, VirtualBox<span style="color:#ff79c6">)</span> and the operating systems of the virtual machines that you are using?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2024-04-07 14:54:43,764 INFO  NEXT ACTION: <span style="color:#8be9fd;font-style:italic">COMMAND</span> <span style="color:#ff79c6">=</span> ask_user  <span style="color:#8be9fd;font-style:italic">ARGUMENTS</span> <span style="color:#ff79c6">=</span> <span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#39;question&#39;</span>: <span style="color:#f1fa8c">&#39;Could you please specify the virtual machine environment (e.g., VMWare, VirtualBox) and the operating systems of the virtual machines that you are using?&#39;</span><span style="color:#ff79c6">}</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:54:43,764 INFO  Enter <span style="color:#f1fa8c">&#39;y&#39;</span> to authorise command, <span style="color:#f1fa8c">&#39;y -N&#39;</span> to run N continuous commands, <span style="color:#f1fa8c">&#39;n&#39;</span> to <span style="color:#8be9fd;font-style:italic">exit</span> program, or enter feedback <span style="color:#ff79c6">for</span> GoVMDiskMonitorGPT...
</span></span><span style="display:flex;"><span>Input: 2024-04-07 14:54:43,765 WARNING  Invalid input format.
</span></span><span style="display:flex;"><span>Input: y
</span></span><span style="display:flex;"><span>2024-04-07 14:54:51,006 INFO  -<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span> COMMAND AUTHORISED BY USER -<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Q: Could you please specify the virtual machine environment <span style="color:#ff79c6">(</span>e.g., VMWare, VirtualBox<span style="color:#ff79c6">)</span> and the operating systems of the virtual machines that you are using?
</span></span><span style="display:flex;"><span>A:
</span></span><span style="display:flex;"><span>2024-04-07 14:55:35,296 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions <span style="color:#f1fa8c">&#34;HTTP/1.1 200 OK&#34;</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:55:35,300 INFO  SYSTEM: The user<span style="color:#f1fa8c">&#39;s answer: &#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,976 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions &#34;HTTP/1.1 200 OK&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,993 INFO  GOVMDISKMONITORGPT THOUGHTS: Without specific details on the virtual machine environment and operating system, the strategy must be adjusted to provide a more generalized approach to monitoring disk space using Go. Assuming a common scenario, the monitoring tool will need to be adaptable to various environments potentially including both Windows and Linux systems.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,994 INFO  REASONING: The versatility of Go allows for the creation of cross-platform tools. System calls or external tools like `df` on Unix systems can be invoked to gather disk usage metrics. For Windows, Go&#39;</span>s <span style="color:#f1fa8c">`</span>syscall<span style="color:#f1fa8c">`</span> package can be leveraged. Given the constraints, detailed operating system-specific strategies can<span style="color:#f1fa8c">&#39;t be designed, but guidelines can be provided.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,994 INFO  PLAN:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,994 INFO  -  Propose a generalized approach for a Go-based disk monitoring tool.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,995 INFO  -  Include considerations for both Windows and Linux environments.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,995 INFO  -  Suggest improvements and user actions for a more tailored approach if further information is provided.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,995 INFO  CRITICISM: Failing to solicit the needed information from the user limited the ability to tailor the monitoring tool&#39;</span>s design to their specific environment. Without this information, the proposed solution might not fully meet their needs.
</span></span><span style="display:flex;"><span>2024-04-07 14:55:56,996 INFO  SPEAK: I<span style="color:#f1fa8c">&#39;ll share a basic strategy for setting up a disk space monitoring tool in Go that could be adapted to various environments. If you can provide more specific details on your virtual machine setup later, the strategy could be more precisely tailored to your needs.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,996 INFO  NEXT ACTION: COMMAND = write_to_file  ARGUMENTS = {&#39;</span>filename<span style="color:#f1fa8c">&#39;: &#39;</span>disk_monitoring_strategy.md<span style="color:#f1fa8c">&#39;, &#39;</span>contents<span style="color:#f1fa8c">&#39;: &#34;# Disk Space Monitoring Tool Strategy in Go\n\nThis document outlines a basic strategy for implementing a disk space monitoring tool in Go, adaptable to multiple environments including both Windows and Linux systems.\n\n## General Strategy\n\n- Use Go&#39;</span>s <span style="color:#f1fa8c">`</span>os<span style="color:#f1fa8c">`</span> and <span style="color:#f1fa8c">`</span>syscall<span style="color:#f1fa8c">`</span> packages to interact with the operating system and retrieve disk space usage.<span style="color:#f1fa8c">\n</span>- For Linux environments, consider invoking external commands like <span style="color:#f1fa8c">`</span>df<span style="color:#f1fa8c">`</span> using Go<span style="color:#f1fa8c">&#39;s `os/exec` package to get disk usage information.\n- For Windows, leverage the `syscall` package to access system calls related to disk space information.\n\n## Key Considerations\n\n- Implement error handling to address the potential failures of external commands or system calls.\n- Ensure the monitoring tool can run across different operating systems by abstracting OS-specific functionality.\n- Optimize the tool&#39;</span>s performance to minimize its impact on system resources.<span style="color:#f1fa8c">\n</span>- Enhance the tool with logging capabilities <span style="color:#ff79c6">for</span> tracking disk usage over <span style="color:#8be9fd;font-style:italic">time</span> and alerting when thresholds are exceeded.<span style="color:#f1fa8c">\n\n</span>Further refinement could be achieved with more specific details on the virtual machine environment and operating systems in use. The user is encouraged to provide this information <span style="color:#ff79c6">for</span> a more tailored approach.<span style="color:#f1fa8c">&#34;}
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:55:56,996 INFO  Enter &#39;y&#39; to authorise command, &#39;y -N&#39; to run N continuous commands, &#39;n&#39; to exit program, or enter feedback for GoVMDiskMonitorGPT...
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Input: y
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:56:04,972 INFO  -=-=-=-=-=-=-= COMMAND AUTHORISED BY USER -=-=-=-=-=-=-=
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:56:04,972 WARNING  write_to_file(filename=&#39;disk_monitoring_strategy.md&#39;, contents=&#34;</span><span style="color:#6272a4"># Disk Space Monitoring Tool Strategy in Go\n\nThis document outlines a basic strategy for implementing a disk space monitoring tool in Go, adaptable to multiple environments including both Windows and Linux systems.\n\n## General Strategy\n\n- Use Go&#39;s `os` and `syscall` packages to interact with the operating system and retrieve disk space usage.\n- For Linux environments, consider invoking external commands like `df` using Go&#39;s `os/exec` package to get disk usage information.\n- For Windows, leverage the `syscall` package to access system calls related to disk space information.\n\n## Key Considerations\n\n- Implement error handling to address the potential failures of external commands or system calls.\n- Ensure the monitoring tool can run across different operating systems by abstracting OS-specific functionality.\n- Optimize the tool&#39;s performance to minimize its impact on system resources.\n- Enhance the tool with logging capabilities for tracking disk usage over time and alerting when thresholds are exceeded.\n\nFurther refinement could be achieved with more specific details on the virtual machine environment and operating systems in use. The user is encouraged to provide this information for a more tailored approach.&#34;) raised an error: Cannot execute command &#39;write_to_file&#39;: unknown command.</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:56:06,836 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions <span style="color:#f1fa8c">&#34;HTTP/1.1 200 OK&#34;</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:56:06,839 WARNING  Command write_to_file returned an error: UnknownCommandError<span style="color:#ff79c6">(</span><span style="color:#f1fa8c">&#34;Cannot execute command &#39;write_to_file&#39;: unknown command.&#34;</span><span style="color:#ff79c6">)</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,687 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions <span style="color:#f1fa8c">&#34;HTTP/1.1 200 OK&#34;</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,723 INFO  GOVMDISKMONITORGPT THOUGHTS: I aimed to provide a general documentation strategy <span style="color:#ff79c6">for</span> disk monitoring without specific user input on the environment, which led to an aborted attempt due to <span style="color:#8be9fd;font-style:italic">command</span> choice error.
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,724 INFO  REASONING: Given my intention was to document a general strategy, and the <span style="color:#f1fa8c">&#39;write_file&#39;</span> <span style="color:#8be9fd;font-style:italic">command</span> is what I should have used instead of <span style="color:#f1fa8c">&#39;write_to_file&#39;</span>. There appears to have been a misunderstanding or mistake in <span style="color:#8be9fd;font-style:italic">command</span> selection.
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,724 INFO  PLAN:
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,724 INFO  -  Review and use the correct <span style="color:#8be9fd;font-style:italic">command</span> from the provided list.
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,725 INFO  -  Perform an action that advances towards the goal, taking into account the mistake and correcting course.
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,725 INFO  -  Consider using <span style="color:#f1fa8c">&#39;write_file&#39;</span> correctly to achieve the documentation strategy output.
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,725 INFO  CRITICISM: I erred in choosing the correct command, highlighting a lapse in paying close attention to the provided commands. This mistake could have been avoided by more meticulously reviewing the <span style="color:#8be9fd;font-style:italic">command</span> list.
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,725 INFO  SPEAK: I encountered an issue with the <span style="color:#8be9fd;font-style:italic">command</span> used. Let me correct this and proceed with our strategy documentation.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,726 INFO  NEXT ACTION: <span style="color:#8be9fd;font-style:italic">COMMAND</span> <span style="color:#ff79c6">=</span> write_file  <span style="color:#8be9fd;font-style:italic">ARGUMENTS</span> <span style="color:#ff79c6">=</span> <span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#39;filename&#39;</span>: <span style="color:#f1fa8c">&#39;disk_monitoring_strategy.md&#39;</span>, <span style="color:#f1fa8c">&#39;contents&#39;</span>: <span style="color:#f1fa8c">&#34;# Disk Space Monitoring Tool Strategy in Go\n\nThis document outlines a basic strategy for implementing a disk space monitoring tool in Go, adaptable to multiple environments including both Windows and Linux systems.\n\n## General Strategy\n\n- Use Go&#39;s `os` and `syscall` packages to interact with the operating system and retrieve disk space usage.\n- For Linux environments, consider invoking external commands like `df` using Go&#39;s `os/exec` package to get disk usage information.\n- For Windows, leverage the `syscall` package to access system calls related to disk space information.\n\n## Key Considerations\n\n- Implement error handling to address the potential failures of external commands or system calls.\n- Ensure the monitoring tool can run across different operating systems by abstracting OS-specific functionality.\n- Optimize the tool&#39;s performance to minimize its impact on system resources.\n- Enhance the tool with logging capabilities for tracking disk usage over time and alerting when thresholds are exceeded.\n\nFurther refinement could be achieved with more specific details on the virtual machine environment and operating systems in use. The user is encouraged to provide this information for a more tailored approach.&#34;</span><span style="color:#ff79c6">}</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:56:21,772 INFO  Enter <span style="color:#f1fa8c">&#39;y&#39;</span> to authorise command, <span style="color:#f1fa8c">&#39;y -N&#39;</span> to run N continuous commands, <span style="color:#f1fa8c">&#39;n&#39;</span> to <span style="color:#8be9fd;font-style:italic">exit</span> program, or enter feedback <span style="color:#ff79c6">for</span> GoVMDiskMonitorGPT...
</span></span><span style="display:flex;"><span>Input: y
</span></span><span style="display:flex;"><span>2024-04-07 14:57:46,241 INFO  -<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span> COMMAND AUTHORISED BY USER -<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:57:47,906 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions <span style="color:#f1fa8c">&#34;HTTP/1.1 200 OK&#34;</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:57:47,908 INFO  SYSTEM: File disk_monitoring_strategy.md has been written successfully.
</span></span><span style="display:flex;"><span>2024-04-07 14:57:57,428 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions <span style="color:#f1fa8c">&#34;HTTP/1.1 200 OK&#34;</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:57:57,462 INFO  GOVMDISKMONITORGPT THOUGHTS: After creating a strategy document, the next logical step is to start implementation based on that strategy. Given my operational restrictions, I cannot execute or write Go code directly. However, I can guide the user on how to proceed with implementation or offer more detailed advice on the tool<span style="color:#f1fa8c">&#39;s design.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:57:57,462 INFO  REASONING: The creation of a foundational document is a significant step towards developing the tool. It sets a base for the user to understand what needs to be done. Given the constraint that prohibits direct code execution or development, moving towards an instructional approach is essential. Providing guidance or soliciting more specific details from the user can refine the strategy further.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:57:57,462 INFO  PLAN:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:57:57,462 INFO  -  Clarify or gather more specific requirements from the user regarding VM environments and operating systems.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:57:57,462 INFO  -  Offer guidance on next steps for implementing the strategy.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:57:57,463 INFO  -  Provide examples or best practices for disk monitoring in Go if appropriate.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:57:57,463 INFO  CRITICISM: The creation of the strategy document could be seen as a step that delays direct progress towards implementation. Additionally, not requesting more details upfront from the user about their VM environment might lead to a generic strategy that lacks precision.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:57:57,463 INFO  SPEAK: I&#39;</span>ve prepared a general strategy <span style="color:#ff79c6">for</span> the disk space monitoring tool. Would you like to proceed with more detailed instructions on implementing this in Go, or <span style="color:#ff79c6">do</span> you have any specific requirements or questions?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2024-04-07 14:57:57,463 INFO  NEXT ACTION: <span style="color:#8be9fd;font-style:italic">COMMAND</span> <span style="color:#ff79c6">=</span> ask_user  <span style="color:#8be9fd;font-style:italic">ARGUMENTS</span> <span style="color:#ff79c6">=</span> <span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#39;question&#39;</span>: <span style="color:#f1fa8c">&#39;Would you like to proceed with more detailed instructions on how to implement the disk space monitoring tool in Go, or do you have any specific requirements or questions?&#39;</span><span style="color:#ff79c6">}</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:57:57,484 INFO  Enter <span style="color:#f1fa8c">&#39;y&#39;</span> to authorise command, <span style="color:#f1fa8c">&#39;y -N&#39;</span> to run N continuous commands, <span style="color:#f1fa8c">&#39;n&#39;</span> to <span style="color:#8be9fd;font-style:italic">exit</span> program, or enter feedback <span style="color:#ff79c6">for</span> GoVMDiskMonitorGPT...
</span></span><span style="display:flex;"><span>Input: y
</span></span><span style="display:flex;"><span>2024-04-07 14:58:04,241 INFO  -<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span> COMMAND AUTHORISED BY USER -<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Q: Would you like to proceed with more detailed instructions on how to implement the disk space monitoring tool in Go, or <span style="color:#ff79c6">do</span> you have any specific requirements or questions?
</span></span><span style="display:flex;"><span>A: n
</span></span><span style="display:flex;"><span>2024-04-07 14:58:23,754 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions <span style="color:#f1fa8c">&#34;HTTP/1.1 200 OK&#34;</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:58:23,756 INFO  SYSTEM: The user<span style="color:#f1fa8c">&#39;s answer: &#39;</span>n<span style="color:#f1fa8c">&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">| Thinking...
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:58:30,307 INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions &#34;HTTP/1.1 200 OK&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:58:30,365 INFO  GOVMDISKMONITORGPT THOUGHTS: Given the user&#39;</span>s response, it seems they are either satisfied with the general strategy outlined or may not need further guidance at this moment.
</span></span><span style="display:flex;"><span>2024-04-07 14:58:30,365 INFO  REASONING: As the user has communicated a lack of interest in proceeding with more detailed instructions, it<span style="color:#f1fa8c">&#39;s integral to respect their decision and conclude our assistance unless explicitly requested otherwise.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:58:30,365 INFO  PLAN:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2024-04-07 14:58:30,365 INFO  -  Respect user&#39;</span>s decision and conclude assistance.
</span></span><span style="display:flex;"><span>2024-04-07 14:58:30,366 INFO  -  Offer a final opportunity <span style="color:#ff79c6">for</span> any further questions or clarifications.
</span></span><span style="display:flex;"><span>2024-04-07 14:58:30,366 INFO  -  Close the interaction positively.
</span></span><span style="display:flex;"><span>2024-04-07 14:58:30,366 INFO  CRITICISM: I might have provided more compelling reasons or examples emphasizing the value of further guidance or requested clarification on their specific needs to ensure they have all the necessary information <span style="color:#ff79c6">for</span> their project.
</span></span><span style="display:flex;"><span>2024-04-07 14:58:30,366 INFO  SPEAK: If you have any further questions or need assistance in the future, feel free to reach out. Thank you <span style="color:#ff79c6">for</span> your time!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2024-04-07 14:58:30,366 INFO  NEXT ACTION: <span style="color:#8be9fd;font-style:italic">COMMAND</span> <span style="color:#ff79c6">=</span> finish  <span style="color:#8be9fd;font-style:italic">ARGUMENTS</span> <span style="color:#ff79c6">=</span> <span style="color:#ff79c6">{</span><span style="color:#f1fa8c">&#39;reason&#39;</span>: <span style="color:#f1fa8c">&#39;User indicated no further need for assistance at this stage.&#39;</span><span style="color:#ff79c6">}</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:58:30,366 INFO  Enter <span style="color:#f1fa8c">&#39;y&#39;</span> to authorise command, <span style="color:#f1fa8c">&#39;y -N&#39;</span> to run N continuous commands, <span style="color:#f1fa8c">&#39;n&#39;</span> to <span style="color:#8be9fd;font-style:italic">exit</span> program, or enter feedback <span style="color:#ff79c6">for</span> GoVMDiskMonitorGPT...
</span></span><span style="display:flex;"><span>Input: 2024-04-07 14:58:30,370 WARNING  Invalid input format.
</span></span><span style="display:flex;"><span>Input: y
</span></span><span style="display:flex;"><span>2024-04-07 14:58:37,614 INFO  -<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span> COMMAND AUTHORISED BY USER -<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>-<span style="color:#ff79c6">=</span>
</span></span><span style="display:flex;"><span>2024-04-07 14:58:37,614 INFO  Saving state of GoVMDiskMonitorGPT-07d8f7e6...
</span></span><span style="display:flex;"><span>Press enter to save as <span style="color:#f1fa8c">&#39;GoVMDiskMonitorGPT-07d8f7e6&#39;</span>, or enter a different ID to save to:
</span></span></code></pre></div><h1 id="autogen">AutoGen</h1>
<h2 id="简介">简介</h2>
<p>AutoGen是一个框架,可以通过使用多个可以相互对话以完成任务的代理来开发LLM应用程序。AutoGen代理是可定制的,可交谈的,并可以无缝地允许人工参与。它们可以以多种模式运行,这些模式结合使用LLM、人类输入和工具。</p>
<p>
  <img src="https://microsoft.github.io/autogen/assets/images/autogen_agentchat-250ca64b77b87e70d34766a080bf6ba8.png" alt="autogen_agentchat">

</p>
<p>主要特性：</p>
<ul>
<li>AutoGen可以轻松构建基于多代理对话的下一代LLM应用程序。它简化了复杂的 LLM工作流程的编排、自动化和优化。它最大限度地提高了 LLM 模型的性能并克服了它们的弱点。</li>
<li>它支持复杂工作流程的多种对话模式。借助可定制和可对话的代理，开发人员可以使用 AutoGen 构建各种涉及对话自主性、代理数量和代理对话拓扑的对话模式。</li>
<li>它提供了一系列具有不同复杂性的工作系统。这些系统涵盖 各种领域和复杂性的广泛应用。这演示了 AutoGen 如何轻松支持不同的对话模式。</li>
</ul>
<h2 id="安装">安装</h2>
<p>通过conda安装python虚拟环境</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>conda create -n pyautogen <span style="color:#8be9fd;font-style:italic">python</span><span style="color:#ff79c6">=</span>3.10
</span></span><span style="display:flex;"><span>conda activate pyautogen
</span></span></code></pre></div><p>安装autogen</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install pyautogen docker
</span></span></code></pre></div><p>建议使用Docker用于代码执行，autogen跟docker做了集成，官网集成docker指引：<a href="https://microsoft.github.io/autogen/docs/installation/Docker">https://microsoft.github.io/autogen/docs/installation/Docker</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#6272a4"># 一个简单的例子：如何使用docker用于代码执行</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> pathlib <span style="color:#ff79c6">import</span> Path
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> UserProxyAgent
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen.coding <span style="color:#ff79c6">import</span> DockerCommandLineCodeExecutor
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    work_dir <span style="color:#ff79c6">=</span> Path(<span style="color:#f1fa8c">&#34;coding&#34;</span>)
</span></span><span style="display:flex;"><span>    work_dir<span style="color:#ff79c6">.</span>mkdir(exist_ok<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">with</span> DockerCommandLineCodeExecutor(work_dir<span style="color:#ff79c6">=</span>work_dir) <span style="color:#ff79c6">as</span> code_executor:
</span></span><span style="display:flex;"><span>        user_proxy <span style="color:#ff79c6">=</span> UserProxyAgent(
</span></span><span style="display:flex;"><span>            name<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;user_proxy&#34;</span>,
</span></span><span style="display:flex;"><span>            code_execution_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;executor&#34;</span>: code_executor},
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>官方推荐把autogen程序封装在Docker里执行，确保环境执行的一致性</p>
<h2 id="实践">实践</h2>
<h3 id="conversableagent">ConversableAgent</h3>
<p>在autogen中，Agent是一个实体，可以向环境中的其它Agent发送、接收消息。Agent可以由模型、代码执行器(ipython内核)、tool执行器、human输入或其它定制组件的组合来支持。比如内置的<code>ConversableAgent</code>就属于这种。</p>
<p>
  <img src="https://microsoft.github.io/autogen/assets/images/conversable-agent-58656a6f9b08b1d7d942a358e22a28bb.jpg" alt="ConversableAgent">

</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#6272a4"># 这里的模型对接了本地的ollama，后端是qwen:7b模型</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://openllm.xxx.com/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    agent <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;chatbot&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Turn off code execution, by default it is off.</span>
</span></span><span style="display:flex;"><span>        code_execution_config<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>,
</span></span><span style="display:flex;"><span>        function_map<span style="color:#ff79c6">=</span><span style="color:#ff79c6">None</span>,  <span style="color:#6272a4"># No registered functions, by default it is None.</span>
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    reply <span style="color:#ff79c6">=</span> agent<span style="color:#ff79c6">.</span>generate_reply(
</span></span><span style="display:flex;"><span>        messages<span style="color:#ff79c6">=</span>[{<span style="color:#f1fa8c">&#34;content&#34;</span>: <span style="color:#f1fa8c">&#34;Tell me a joke.&#34;</span>, <span style="color:#f1fa8c">&#34;role&#34;</span>: <span style="color:#f1fa8c">&#34;user&#34;</span>}])
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd;font-style:italic">print</span>(reply)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>Sure, here&#39;s a classic joke for you:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Why don&#39;t scientists trust atoms?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Because they make up everything!
</span></span></code></pre></div><p>引入角色和对话</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#6272a4"># 引入角色和对话，分配两个agent，并设置system_message</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://openllm.xxx.com/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cathy <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;cathy&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Your name is Cathy and you are a part of a duo of comedians.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    joe <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;joe&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Your name is Joe and you are a part of a duo of comedians.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># 初始化聊天，max_turns控制对话的回合数，一来一回算一次</span>
</span></span><span style="display:flex;"><span>    joe<span style="color:#ff79c6">.</span>initiate_chat(cathy, message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Cathy, tell me a joke.&#34;</span>, max_turns<span style="color:#ff79c6">=</span><span style="color:#bd93f9">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>joe (to cathy):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Cathy, tell me a joke.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>cathy (to joe):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Sure, here&#39;s a classic joke for you:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Why don&#39;t scientists trust atoms?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Because they make up everything!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>joe (to cathy):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Joe, that&#39;s a great one! I think audiences would really enjoy it. Let&#39;s see if we can come up with something similar but still fresh and funny.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Here&#39;s a potential follow-up joke:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Why did the tomato turn red?
</span></span><span style="display:flex;"><span>Because it saw the salad dressing! 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>This one plays on the visual pun of tomatoes turning red when they&#39;re exposed to acid, which is what salad dressings contain.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>No default IOStream has been set, defaulting to IOConsole.
</span></span><span style="display:flex;"><span>cathy (to joe):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>That&#39;s a great follow-up joke, Cathy! It cleverly builds on the visual pun and adds a humorous twist. Audiences are sure to enjoy this play on words.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span></code></pre></div><h3 id="终止会话">终止会话</h3>
<p>Agent之间的对话终止，有两种机制控制：</p>
<ul>
<li>配置<code>initiate_chat</code>的参数</li>
<li>配置Agent触发终止</li>
</ul>
<h4 id="initiate_chat参数控制">initiate_chat参数控制</h4>
<p><code>initiate_chat</code>的max_turns参数控制，比如max_tures=3</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#6272a4"># 引入角色和对话，分配两个agent，并设置system_message</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://openllm.xxx.com/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cathy <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;cathy&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Your name is Cathy and you are a part of a duo of comedians.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    joe <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;joe&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Your name is Joe and you are a part of a duo of comedians.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    joe<span style="color:#ff79c6">.</span>initiate_chat(cathy, message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Cathy, tell me a joke.&#34;</span>,
</span></span><span style="display:flex;"><span>                      max_turns<span style="color:#ff79c6">=</span><span style="color:#bd93f9">3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>joe (to cathy):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Cathy, tell me a joke.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>cathy (to joe):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Sure, here&#39;s a classic joke for you:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Why don&#39;t scientists trust atoms?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Because they make up everything!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>joe (to cathy):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Joe, that&#39;s a great one! I think audiences would really enjoy it. Let&#39;s see if we can come up with something similar but still fresh and funny.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Here&#39;s a potential follow-up joke:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Why did the tomato turn red?
</span></span><span style="display:flex;"><span>Because it saw the salad dressing! 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>This one plays on the visual pun of tomatoes turning red when they&#39;re exposed to acid, which is what salad dressings contain.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>cathy (to joe):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>That&#39;s a great follow-up joke, Cathy! It cleverly builds on the visual pun and adds a humorous twist. Audiences are sure to enjoy this play on words.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>joe (to cathy):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Thank you, Joe! I&#39;m glad you think so. Comedians often rely on wordplay and unexpected twists to create laughter. It&#39;s a skill that takes practice but can be incredibly rewarding when it clicks with an audience.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>cathy (to joe):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Absolutely, Cathy! Comedians like ourselves understand the power of humor and how it can connect with people in various ways. The ability to craft jokes that resonate, while also being adaptable to different audiences, is what makes comedy a fulfilling art form.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span></code></pre></div><h4 id="agent触发终止">Agent触发终止</h4>
<p>可以为Agent配置参数用于终止对话，有两种参数可以配置：</p>
<ul>
<li><code>max_consecutive_auto_reply</code>：对同一发送人的自动响应数量</li>
<li><code>is_terminate_msg</code>：接收到终止的关键词就终止对话</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#6272a4"># 使用max_consecutive_auto_reply控制Agent终止对话</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># max_consecutive_auto_reply=1，joe对cathy的响应回复只会有一条</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://openllm.xxx.com/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cathy <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;cathy&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Your name is Cathy and you are a part of a duo of comedians.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    joe <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;joe&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Your name is Joe and you are a part of a duo of comedians.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>        max_consecutive_auto_reply<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    joe<span style="color:#ff79c6">.</span>initiate_chat(cathy, message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Cathy, tell me a joke.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>joe (to cathy):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Cathy, tell me a joke.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>cathy (to joe):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Sure, here&#39;s a classic joke for you:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Why don&#39;t scientists trust atoms?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Because they make up everything!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>joe (to cathy):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Joe, that&#39;s a great one! I think audiences would really enjoy it. Let&#39;s see if we can come up with something similar but still fresh and funny.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Here&#39;s a potential follow-up joke:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Why did the tomato turn red?
</span></span><span style="display:flex;"><span>Because it saw the salad dressing! 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>This one plays on the visual pun of tomatoes turning red when they&#39;re exposed to acid, which is what salad dressings contain.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>cathy (to joe):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>That&#39;s a great follow-up joke, Cathy! It cleverly builds on the visual pun and adds a humorous twist. Audiences are sure to enjoy this play on words.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#6272a4"># 使用is_termination_msg控制Agent终止对话</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># joe接收到cathy的goodbye关键词就会终止对话</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://openllm.xxx.com/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cathy <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;cathy&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Your name is Cathy and you are a part of a duo of comedians.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    joe <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;joe&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Your name is Joe and you are a part of a duo of comedians.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># Never ask for human input.</span>
</span></span><span style="display:flex;"><span>        is_termination_msg<span style="color:#ff79c6">=</span><span style="color:#ff79c6">lambda</span> msg: <span style="color:#f1fa8c">&#34;goodbye&#34;</span> <span style="color:#ff79c6">in</span> msg[<span style="color:#f1fa8c">&#34;content&#34;</span>]<span style="color:#ff79c6">.</span>lower()
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    joe<span style="color:#ff79c6">.</span>initiate_chat(cathy, message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Cathy, tell me a joke and then say the words GOOD BYE.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>joe (to cathy):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Cathy, tell me a joke and then say the words GOOD BYE.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>cathy (to joe):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Sure, here&#39;s a joke for you:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Why don&#39;t scientists trust atoms?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Because they make up everything!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Now, let&#39;s say those words together:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Goodbye!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span></code></pre></div><h3 id="人工循环">人工循环</h3>
<p>autogen支持在Agent中进行人工干预，使用ConversableAgent的human-the-loop组件。

  <img src="https://microsoft.github.io/autogen/assets/images/human-in-the-loop-56dc002683ab4481042ffd3d346d1759.png" alt="human-in-the-loop">


如图所示，human-the-loop组件在auto-reply组件之前，消息先进入到human-the-loop组件，然后它在决定到human-reply还是到auto-reply</p>
<p>CoversableAgent中的人工输入模式human_input_mode支持三种：</p>
<ul>
<li>NEVER：不要求人工输入</li>
<li>TERMINATE(默认值)：仅当满足终止条件时才请求人工输入，在这个模式下，如果选择拦截并回复，则对话将继续，并且使用到的计数器<code>max_consectuive_auto_reply</code>也会被重制</li>
<li>ALWAYS：始终需要人工输入，并且人工可以选择跳过并触发自动回复、拦截并提供反馈或终止对话，<code>max_consecutive_auto_reply</code>这个值设置无效</li>
</ul>
<h4 id="人工输入模式never">人工输入模式=NEVER</h4>
<p>human_input_mode设置为never，下面demo是猜数字游戏，猜到53就结束</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> gevent <span style="color:#ff79c6">import</span> config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://openllm.xxx.com/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    agent_with_number <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;agent_with_number&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;You are playing a game of guess-my-number. You have the &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;number 53 in your mind, and I will try to guess it. &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;If I guess too high, say &#39;too high&#39;, if I guess too low, say &#39;too low&#39;. &#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># terminate if the number is guessed by the other agent</span>
</span></span><span style="display:flex;"><span>        is_termination_msg<span style="color:#ff79c6">=</span><span style="color:#ff79c6">lambda</span> msg: <span style="color:#f1fa8c">&#34;53&#34;</span> <span style="color:#ff79c6">in</span> msg[<span style="color:#f1fa8c">&#34;content&#34;</span>],
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># never ask for human input</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    agent_guess_number <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;agent_guess_number&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;I have a number in my mind, and you will try to guess it. &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;If I say &#39;too high&#39;, you should guess a lower number. If I say &#39;too low&#39;, &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;you should guess a higher number. &#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    result <span style="color:#ff79c6">=</span> agent_with_number<span style="color:#ff79c6">.</span>initiate_chat(
</span></span><span style="display:flex;"><span>        agent_guess_number,
</span></span><span style="display:flex;"><span>        message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;I have a number between 1 and 100. Guess it!&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>agent_with_number <span style="color:#ff79c6">(</span>to agent_guess_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>I have a number between <span style="color:#bd93f9">1</span> and 100. Guess it!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_guess_number <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>I<span style="color:#f1fa8c">&#39;ll start with a guess that&#39;</span>s not too high or too low. Let<span style="color:#f1fa8c">&#39;s try 50.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">--------------------------------------------------------------------------------
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">agent_with_number (to agent_guess_number):
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Too low! The number I&#39;</span>m thinking of is higher than 50. Keep trying!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_guess_number <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Alright, let<span style="color:#f1fa8c">&#39;s go for a slightly higher number.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">My next guess would be 75.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">--------------------------------------------------------------------------------
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">agent_with_number (to agent_guess_number):
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Too high! The number I was thinking of is actually lower than 75. Let&#39;</span>s try again with a slightly lower estimate.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_guess_number <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Understood. My next guess will be a bit closer to the actual number.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>My new guess: 68.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_with_number <span style="color:#ff79c6">(</span>to agent_guess_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Close, but still too low! The number I had in mind is higher than 68. Let<span style="color:#f1fa8c">&#39;s try one more time with an estimate that&#39;</span>s slightly above 68.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_guess_number <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Understood. My final guess will be a bit higher than <span style="color:#bd93f9">68</span> to account <span style="color:#ff79c6">for</span> the higher number you<span style="color:#f1fa8c">&#39;re thinking of.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">My last guess: 72.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">If this is the correct number, please let me know so I can congratulate you!
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">--------------------------------------------------------------------------------
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">agent_with_number (to agent_guess_number):
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Congratulations! You&#39;</span>ve guessed the correct number. The number I was thinking of is indeed 72. Well <span style="color:#ff79c6">done</span>!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span></code></pre></div><h4 id="人工输入模式terminate">人工输入模式=TERMINATE</h4>
<p>human_input_mode设置为TERMINATE，设置了max_consecutive_auto_reply=1和is_termination_msg，一旦触发就需要手工确认
是继续还是终止</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://openllm.xxx.com/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    agent_with_number <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;agent_with_number&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;You are playing a game of guess-my-number. &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;In the first game, you have the &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;number 53 in your mind, and I will try to guess it. &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;If I guess too high, say &#39;too high&#39;, if I guess too low, say &#39;too low&#39;. &#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># maximum number of consecutive auto-replies before asking for human input</span>
</span></span><span style="display:flex;"><span>        max_consecutive_auto_reply<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># terminate if the number is guessed by the other agent</span>
</span></span><span style="display:flex;"><span>        is_termination_msg<span style="color:#ff79c6">=</span><span style="color:#ff79c6">lambda</span> msg: <span style="color:#f1fa8c">&#34;53&#34;</span> <span style="color:#ff79c6">in</span> msg[<span style="color:#f1fa8c">&#34;content&#34;</span>],
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;TERMINATE&#34;</span>,  <span style="color:#6272a4"># ask for human input until the game is terminated</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    agent_guess_number <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;agent_guess_number&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;I have a number in my mind, and you will try to guess it. &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;If I say &#39;too high&#39;, you should guess a lower number. If I say &#39;too low&#39;, &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;you should guess a higher number. &#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    result <span style="color:#ff79c6">=</span> agent_with_number<span style="color:#ff79c6">.</span>initiate_chat(
</span></span><span style="display:flex;"><span>        agent_guess_number,
</span></span><span style="display:flex;"><span>        message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;I have a number between 1 and 100. Guess it!&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>agent_with_number <span style="color:#ff79c6">(</span>to agent_guess_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>I have a number between <span style="color:#bd93f9">1</span> and 100. Guess it!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_guess_number <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>I<span style="color:#f1fa8c">&#39;ll start with a guess that&#39;</span>s not too high or too low. Let<span style="color:#f1fa8c">&#39;s try 50.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">--------------------------------------------------------------------------------
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; USING AUTO REPLY...
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">agent_with_number (to agent_guess_number):
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Too low! The number I&#39;</span>m thinking of is higher than 50. Keep trying!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_guess_number <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Alright, let<span style="color:#f1fa8c">&#39;s go for a slightly higher number.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">My next guess would be 75.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">--------------------------------------------------------------------------------
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Please give feedback to agent_guess_number. Press enter to skip and use auto-reply, or type &#39;</span>exit&#39; to stop the conversation: <span style="color:#8be9fd;font-style:italic">exit</span>
</span></span></code></pre></div><h4 id="人工输入模式always">人工输入模式=ALWAYS</h4>
<p>human_input_mode设置为ALWAYS，每次都需要人工输入</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> gevent <span style="color:#ff79c6">import</span> config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://openllm.llschain.com/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    agent_with_number <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;agent_with_number&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;You are playing a game of guess-my-number. You have the &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;number 53 in your mind, and I will try to guess it. &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;If I guess too high, say &#39;too high&#39;, if I guess too low, say &#39;too low&#39;. &#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># terminate if the number is guessed by the other agent</span>
</span></span><span style="display:flex;"><span>        is_termination_msg<span style="color:#ff79c6">=</span><span style="color:#ff79c6">lambda</span> msg: <span style="color:#f1fa8c">&#34;53&#34;</span> <span style="color:#ff79c6">in</span> msg[<span style="color:#f1fa8c">&#34;content&#34;</span>],
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,  <span style="color:#6272a4"># never ask for human input</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    human_proxy <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;human_proxy&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>,  <span style="color:#6272a4"># no LLM used for human proxy</span>
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;ALWAYS&#34;</span>,  <span style="color:#6272a4"># always ask for human input</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    result <span style="color:#ff79c6">=</span> human_proxy<span style="color:#ff79c6">.</span>initiate_chat(
</span></span><span style="display:flex;"><span>        agent_with_number,
</span></span><span style="display:flex;"><span>        message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;10&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>human_proxy <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#bd93f9">10</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_with_number <span style="color:#ff79c6">(</span>to human_proxy<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>too low
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or <span style="color:#8be9fd;font-style:italic">type</span> <span style="color:#f1fa8c">&#39;exit&#39;</span> to end the conversation: <span style="color:#bd93f9">12</span>
</span></span><span style="display:flex;"><span>human_proxy <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#bd93f9">12</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_with_number <span style="color:#ff79c6">(</span>to human_proxy<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>still too low
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or <span style="color:#8be9fd;font-style:italic">type</span> <span style="color:#f1fa8c">&#39;exit&#39;</span> to end the conversation: <span style="color:#bd93f9">54</span>
</span></span><span style="display:flex;"><span>human_proxy <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#bd93f9">54</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_with_number <span style="color:#ff79c6">(</span>to human_proxy<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>too high
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or <span style="color:#8be9fd;font-style:italic">type</span> <span style="color:#f1fa8c">&#39;exit&#39;</span> to end the conversation: <span style="color:#bd93f9">52</span>
</span></span><span style="display:flex;"><span>human_proxy <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#bd93f9">52</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>agent_with_number <span style="color:#ff79c6">(</span>to human_proxy<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>close! but still too low
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>Provide feedback to agent_with_number. Press enter to skip and use auto-reply, or <span style="color:#8be9fd;font-style:italic">type</span> <span style="color:#f1fa8c">&#39;exit&#39;</span> to end the conversation: <span style="color:#bd93f9">53</span>
</span></span><span style="display:flex;"><span>human_proxy <span style="color:#ff79c6">(</span>to agent_with_number<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#bd93f9">53</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span></code></pre></div><h3 id="代码执行器">代码执行器</h3>
<h4 id="本地执行">本地执行</h4>
<p>
  <img src="https://microsoft.github.io/autogen/assets/images/code-executor-no-docker-0ec717a62637ff02e852efa284dd50d5.png" alt="代码执行器">

</p>
<p>安装相关python库</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># pip install matplotlib numpy</span>
</span></span></code></pre></div><p>一个本地调用执行python脚本的例子</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> tempfile
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen.coding <span style="color:#ff79c6">import</span> LocalCommandLineCodeExecutor
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create a temporary directory to store the code files.</span>
</span></span><span style="display:flex;"><span>    temp_dir <span style="color:#ff79c6">=</span> tempfile<span style="color:#ff79c6">.</span>TemporaryDirectory()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create a local command line code executor.</span>
</span></span><span style="display:flex;"><span>    executor <span style="color:#ff79c6">=</span> LocalCommandLineCodeExecutor(
</span></span><span style="display:flex;"><span>        timeout<span style="color:#ff79c6">=</span><span style="color:#bd93f9">10</span>,  <span style="color:#6272a4"># Timeout for each code execution in seconds.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Use the temporary directory to store the code files.</span>
</span></span><span style="display:flex;"><span>        work_dir<span style="color:#ff79c6">=</span>temp_dir<span style="color:#ff79c6">.</span>name,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create an agent with code executor configuration.</span>
</span></span><span style="display:flex;"><span>    code_executor_agent <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;code_executor_agent&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>,  <span style="color:#6272a4"># Turn off LLM for this agent.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Use the local command line code executor.</span>
</span></span><span style="display:flex;"><span>        code_execution_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;executor&#34;</span>: executor},
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Always take human input for this agent for safety.</span>
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;ALWAYS&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    message_with_code_block <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#34;&#34;&#34;This is a message with code block.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">The code block is below:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">```python
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">import numpy as np
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">import matplotlib.pyplot as plt
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">x = np.random.randint(0, 100, 100)
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">y = np.random.randint(0, 100, 100)
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">plt.scatter(x, y)
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">plt.savefig(&#39;scatter.png&#39;)
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">print(&#39;Scatter plot saved to scatter.png&#39;)
</span></span></span></code></pre></div><p>This is the end of the message.
&quot;&quot;&quot;</p>
<pre><code># Generate a reply for the given code.
reply = code_executor_agent.generate_reply(
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message_with_code_block}])
print(reply)
print(temp_dir.name)
print(os.listdir(temp_dir.name))
</code></pre>
<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:
main()</p>
<pre tabindex="0"><code>
输出：
```bash
Provide feedback to the sender. Press enter to skip and use auto-reply, or type &#39;exit&#39; to end the conversation: 

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; NO HUMAN INPUT RECEIVED.

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; USING AUTO REPLY...

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; EXECUTING CODE BLOCK (inferred language is python)...
exitcode: 0 (execution succeeded)
Code output: 0.00s - Debugger warning: It seems that frozen modules are being used, which may
0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
0.00s - to python to disable frozen modules.
0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
Scatter plot saved to scatter.png

/var/folders/vm/ry3ff3355gnfvmgt8w17872c0000gn/T/tmpccqhl6ds
[&#39;tmp_code_e24bf32d4a21990fb9e4b5eb889ebe5a.py&#39;, &#39;scatter.png&#39;]
</code></pre><h4 id="docker执行">Docker执行</h4>
<p>需要在环境上先装好docker

  <img src="https://microsoft.github.io/autogen/assets/images/code-executor-docker-8d3f56a6bb4b4605fec68804350f42fc.png" alt="">

</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> tempfile
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen.coding <span style="color:#ff79c6">import</span> DockerCommandLineCodeExecutor
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create a temporary directory to store the code files.</span>
</span></span><span style="display:flex;"><span>    temp_dir <span style="color:#ff79c6">=</span> tempfile<span style="color:#ff79c6">.</span>TemporaryDirectory()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create a Docker command line code executor.</span>
</span></span><span style="display:flex;"><span>    executor <span style="color:#ff79c6">=</span> DockerCommandLineCodeExecutor(
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Execute code using the given docker image name.</span>
</span></span><span style="display:flex;"><span>        image<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;python:3.12-slim&#34;</span>,
</span></span><span style="display:flex;"><span>        timeout<span style="color:#ff79c6">=</span><span style="color:#bd93f9">10</span>,  <span style="color:#6272a4"># Timeout for each code execution in seconds.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Use the temporary directory to store the code files.</span>
</span></span><span style="display:flex;"><span>        work_dir<span style="color:#ff79c6">=</span>temp_dir<span style="color:#ff79c6">.</span>name,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create an agent with code executor configuration that uses docker.</span>
</span></span><span style="display:flex;"><span>    code_executor_agent_using_docker <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;code_executor_agent_docker&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>,  <span style="color:#6272a4"># Turn off LLM for this agent.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Use the docker command line code executor.</span>
</span></span><span style="display:flex;"><span>        code_execution_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;executor&#34;</span>: executor},
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Always take human input for this agent for safety.</span>
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;ALWAYS&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    message_with_code_block <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#34;&#34;&#34;This is a message with code block.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">The code block is below:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">```python
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">print(&#39;hello world!&#39;)
</span></span></span></code></pre></div><p>This is the end of the message.
&quot;&quot;&quot;
reply = code_executor_agent_using_docker.generate_reply(
messages=[{&ldquo;role&rdquo;: &ldquo;user&rdquo;, &ldquo;content&rdquo;: message_with_code_block}])
print(reply)</p>
<pre><code># When the code executor is no longer used, stop it to release the resources.
# executor.stop()
</code></pre>
<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:
main()</p>
<pre tabindex="0"><code>
输出：
```bash
Provide feedback to the sender. Press enter to skip and use auto-reply, or type &#39;exit&#39; to end the conversation: 

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; NO HUMAN INPUT RECEIVED.

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; USING AUTO REPLY...

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; EXECUTING CODE BLOCK (inferred language is python)...
exitcode: 0 (execution succeeded)
Code output: hello world!
</code></pre><h4 id="在对话中集成代码执行器">在对话中集成代码执行器</h4>
<p>
  <img src="https://microsoft.github.io/autogen/assets/images/code-execution-in-conversation-f02c7a3ea7e45e3f4aa71d8def851677.png" alt="code-execution-in-conversation">

</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> tempfile
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen.coding <span style="color:#ff79c6">import</span> LocalCommandLineCodeExecutor
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;llama3:8b&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;http://xxx:11434/v1/&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create a temporary directory to store the code files.</span>
</span></span><span style="display:flex;"><span>    temp_dir <span style="color:#ff79c6">=</span> tempfile<span style="color:#ff79c6">.</span>TemporaryDirectory()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create a local command line code executor.</span>
</span></span><span style="display:flex;"><span>    executor <span style="color:#ff79c6">=</span> LocalCommandLineCodeExecutor(
</span></span><span style="display:flex;"><span>        timeout<span style="color:#ff79c6">=</span><span style="color:#bd93f9">10</span>,  <span style="color:#6272a4"># Timeout for each code execution in seconds.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Use the temporary directory to store the code files.</span>
</span></span><span style="display:flex;"><span>        work_dir<span style="color:#ff79c6">=</span>temp_dir<span style="color:#ff79c6">.</span>name,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Create an agent with code executor configuration.</span>
</span></span><span style="display:flex;"><span>    code_executor_agent <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;code_executor_agent&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>,  <span style="color:#6272a4"># Turn off LLM for this agent.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Use the local command line code executor.</span>
</span></span><span style="display:flex;"><span>        code_execution_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;executor&#34;</span>: executor},
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4"># Always take human input for this agent for safety.</span>
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;ALWAYS&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># The code writer agent&#39;s system message is to instruct the LLM on how to use</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># the code executor in the code executor agent.</span>
</span></span><span style="display:flex;"><span>    code_writer_system_message <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#34;&#34;&#34;You are a helpful AI assistant.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Solve tasks using your coding and language skills.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can&#39;t modify your code. So do not suggest incomplete code which requires users to modify. Don&#39;t use a code block if it&#39;s not intended to be executed by the user.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">If you want the user to save the code in a file before executing it, put # filename: &lt;filename&gt; inside the code block as the first line. Don&#39;t include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use &#39;print&#39; function for the output when relevant. Check the execution result returned by the user.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can&#39;t be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Reply &#39;TERMINATE&#39; in the end when everything is done.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    code_writer_agent <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;code_writer_agent&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span>code_writer_system_message,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>        code_execution_config<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>,  <span style="color:#6272a4"># Turn off code execution for this agent.</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    chat_result <span style="color:#ff79c6">=</span> code_executor_agent<span style="color:#ff79c6">.</span>initiate_chat(
</span></span><span style="display:flex;"><span>        code_writer_agent,
</span></span><span style="display:flex;"><span>        message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Write Python code to calculate the 14th Fibonacci number.&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p>输出：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>code_executor_agent <span style="color:#ff79c6">(</span>to code_writer_agent<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Write Python code to calculate the 14th Fibonacci number.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; USING AUTO REPLY...
</span></span><span style="display:flex;"><span>code_writer_agent <span style="color:#ff79c6">(</span>to code_executor_agent<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Here<span style="color:#f1fa8c">&#39;s a simple Python program that calculates the 14th Fibonacci number:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">```python
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"># filename: fibonacci.py
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">def fibonacci(n):
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">    if n &lt;= 0:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">        return &#34;Input should be positive integer.&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">    elif n == 1:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">        return 0
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">    elif n == 2:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">        return 1
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">    else:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">        a, b = 0, 1
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">        for i in range(2, n):
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">            a, b = b, a + b
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">        return b
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">print(fibonacci(14))
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">```
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">To run this code, save it to a file named `fibonacci.py` and then execute the file using Python:
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">```sh
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">$ python fibonacci.py
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">```
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">This program calculates the Fibonacci sequence up to the 14th number. The Fibonacci sequence is a series of numbers in which each number is the sum of the two preceding ones, usually starting with 0 and 1.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">The `fibonacci` function takes an integer `n` as input and returns the `n`-th Fibonacci number. It uses a simple iterative approach to calculate the Fibonacci sequence up to the `n`-th number.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">When you run this code, it will print the 14th Fibonacci number.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">--------------------------------------------------------------------------------
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or type &#39;</span>exit<span style="color:#f1fa8c">&#39; to end the conversation: 
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; NO HUMAN INPUT RECEIVED.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; USING AUTO REPLY...
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; EXECUTING 2 CODE BLOCKS (inferred languages are [python, sh])...
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">code_executor_agent (to code_writer_agent):
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">exitcode: 127 (execution failed)
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Code output: 0.00s - Debugger warning: It seems that frozen modules are being used, which may
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">0.00s - to python to disable frozen modules.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">233
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">/private/var/folders/vm/ry3ff3355gnfvmgt8w17872c0000gn/T/tmphluowg0c/tmp_code_cbdd7e73b49460ad7164185cb78b1d30.sh: line 1: $: command not found
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">--------------------------------------------------------------------------------
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; USING AUTO REPLY...
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">code_writer_agent (to code_executor_agent):
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">It seems that the code I provided earlier is not executable in your environment. The error message indicates that there&#39;</span>s an issue with running Python commands.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>To fix this, let<span style="color:#f1fa8c">&#39;s try a different approach. Instead of executing the code directly, we can use a Python interpreter to run the code and print the result.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">Here&#39;</span>s how you can <span style="color:#ff79c6">do</span> it:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>1. Open a terminal or <span style="color:#8be9fd;font-style:italic">command</span> prompt.
</span></span><span style="display:flex;"><span>2. Type <span style="color:#f1fa8c">`</span>python<span style="color:#f1fa8c">`</span> <span style="color:#ff79c6">(</span>without quotes<span style="color:#ff79c6">)</span> and press Enter.
</span></span><span style="display:flex;"><span>3. In the Python interpreter, <span style="color:#8be9fd;font-style:italic">type</span> the following code:
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">```</span>
</span></span><span style="display:flex;"><span>def fibonacci<span style="color:#ff79c6">(</span>n<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span> n &lt;<span style="color:#ff79c6">=</span> 0:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#f1fa8c">&#34;Input should be positive integer.&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> <span style="color:#8be9fd;font-style:italic">n</span> <span style="color:#ff79c6">==</span> 1:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#bd93f9">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> <span style="color:#8be9fd;font-style:italic">n</span> <span style="color:#ff79c6">==</span> 2:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#bd93f9">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">else</span>:
</span></span><span style="display:flex;"><span>        a, <span style="color:#8be9fd;font-style:italic">b</span> <span style="color:#ff79c6">=</span> 0, <span style="color:#bd93f9">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> i in range<span style="color:#ff79c6">(</span>2, n<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>            a, <span style="color:#8be9fd;font-style:italic">b</span> <span style="color:#ff79c6">=</span> b, a + b
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print<span style="color:#ff79c6">(</span>fibonacci<span style="color:#ff79c6">(</span>14<span style="color:#ff79c6">))</span>
</span></span><span style="display:flex;"><span><span style="color:#f1fa8c">```</span>
</span></span><span style="display:flex;"><span>4. Press Enter to execute the code.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>This should print the 14th Fibonacci number, which is <span style="color:#f1fa8c">`</span>233<span style="color:#f1fa8c">`</span>.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>If you<span style="color:#f1fa8c">&#39;re still having trouble executing the code, please let me know and I&#39;</span>ll try to <span style="color:#8be9fd;font-style:italic">help</span> you further!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or <span style="color:#8be9fd;font-style:italic">type</span> <span style="color:#f1fa8c">&#39;exit&#39;</span> to end the conversation: 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; NO HUMAN INPUT RECEIVED.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; USING AUTO REPLY...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; EXECUTING CODE BLOCK <span style="color:#ff79c6">(</span>inferred language is python<span style="color:#ff79c6">)</span>...
</span></span><span style="display:flex;"><span>code_executor_agent <span style="color:#ff79c6">(</span>to code_writer_agent<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>exitcode: <span style="color:#bd93f9">0</span> <span style="color:#ff79c6">(</span>execution succeeded<span style="color:#ff79c6">)</span>
</span></span><span style="display:flex;"><span>Code output: 0.00s - Debugger warning: It seems that frozen modules are being used, which may
</span></span><span style="display:flex;"><span>0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules<span style="color:#ff79c6">=</span>off
</span></span><span style="display:flex;"><span>0.00s - to python to disable frozen modules.
</span></span><span style="display:flex;"><span>0.00s - Note: Debugging will proceed. Set <span style="color:#8be9fd;font-style:italic">PYDEVD_DISABLE_FILE_VALIDATION</span><span style="color:#ff79c6">=</span><span style="color:#bd93f9">1</span> to disable this validation.
</span></span><span style="display:flex;"><span><span style="color:#bd93f9">233</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; USING AUTO REPLY...
</span></span><span style="display:flex;"><span>code_writer_agent <span style="color:#ff79c6">(</span>to code_executor_agent<span style="color:#ff79c6">)</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>It looks like the code executed successfully and printed the 14th Fibonacci number, which is indeed <span style="color:#f1fa8c">`</span>233<span style="color:#f1fa8c">`</span>. Well <span style="color:#ff79c6">done</span>!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Now that we<span style="color:#f1fa8c">&#39;ve confirmed the correct output, I&#39;</span>ll terminate our conversation.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TERMINATE
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>Provide feedback to code_writer_agent. Press enter to skip and use auto-reply, or <span style="color:#8be9fd;font-style:italic">type</span> <span style="color:#f1fa8c">&#39;exit&#39;</span> to end the conversation: <span style="color:#8be9fd;font-style:italic">exit</span>
</span></span></code></pre></div><h4 id="userproxyagentassistantagent">UserProxyAgent/AssistantAgent</h4>
<p>使用UserProxyAgent/AssistantAgent可以带来便利，避免写system_message，但并不是适用于所有场景，针对特殊的场景，该调整
system_message的还是要调整下</p>
<ul>
<li>UserProxyAgent：ConversableAgent的子类，其中human_input_mode=ALWAYS、llm_config=False、带有默认description，UserProxyAgent通常作为代码执行器</li>
<li>AssistantAgent：ConversableAgent的子类，其中human_input_mode=NEVER、code_execution_config=False、带有默认
description和system_message，AssistantAgent通常作为代码编写器，而不是代码执行器存在</li>
</ul>
<h3 id="工具使用">工具使用</h3>
<p>工具是预定义的函数，Agent可以直接使用；工具调用要正常工作的话需要相应的LLM支持才行，Qwen 1.5开源大模型API支持tool use</p>
<h4 id="创建注册使用工具">创建/注册/使用工具</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> ConversableAgent
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> typing <span style="color:#ff79c6">import</span> Annotated, Literal
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Literal 用于定义一个变量或参数只能取某些字面量值</span>
</span></span><span style="display:flex;"><span>Operator <span style="color:#ff79c6">=</span> Literal[<span style="color:#f1fa8c">&#34;+&#34;</span>, <span style="color:#f1fa8c">&#34;-&#34;</span>, <span style="color:#f1fa8c">&#34;*&#34;</span>, <span style="color:#f1fa8c">&#34;/&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Annotated 则用于为类型添加元数据。它的主要用途是为类型变量添加描述性的字符串。</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">calculator</span>(a: <span style="color:#8be9fd;font-style:italic">int</span>, b: <span style="color:#8be9fd;font-style:italic">int</span>, operator: Annotated[Operator, <span style="color:#f1fa8c">&#34;operator&#34;</span>]) <span style="color:#ff79c6">-&gt;</span> <span style="color:#8be9fd;font-style:italic">int</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span> operator <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;+&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> a <span style="color:#ff79c6">+</span> b
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> operator <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;-&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> a <span style="color:#ff79c6">-</span> b
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> operator <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;*&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> a <span style="color:#ff79c6">*</span> b
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> operator <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;/&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">int</span>(a <span style="color:#ff79c6">/</span> b)
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">raise</span> ValueError(<span style="color:#f1fa8c">&#34;Invalid operator&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">main</span>():
</span></span><span style="display:flex;"><span>    config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;moonshot-v1-8k&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;https://api.moonshot.cn/v1&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;sk-xxx&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;max_tokens&#34;</span>: <span style="color:#bd93f9">8000</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;temperature&#34;</span>: <span style="color:#bd93f9">0</span>,
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Let&#39;s first define the assistant agent that suggests tool calls.</span>
</span></span><span style="display:flex;"><span>    assistant <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        name<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Assistant&#34;</span>,
</span></span><span style="display:flex;"><span>        system_message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;You are a helpful AI assistant. &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;You can help with simple calculations. &#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f1fa8c">&#34;Return &#39;TERMINATE&#39; when the task is done.&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list},
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># The user proxy agent is used for interacting with the assistant agent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># and executes tool calls.</span>
</span></span><span style="display:flex;"><span>    user_proxy <span style="color:#ff79c6">=</span> ConversableAgent(
</span></span><span style="display:flex;"><span>        name<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;User&#34;</span>,
</span></span><span style="display:flex;"><span>        llm_config<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>,
</span></span><span style="display:flex;"><span>        is_termination_msg<span style="color:#ff79c6">=</span><span style="color:#ff79c6">lambda</span> msg: msg<span style="color:#ff79c6">.</span>get(
</span></span><span style="display:flex;"><span>            <span style="color:#f1fa8c">&#34;content&#34;</span>) <span style="color:#ff79c6">is</span> <span style="color:#ff79c6">not</span> <span style="color:#ff79c6">None</span> <span style="color:#ff79c6">and</span> <span style="color:#f1fa8c">&#34;TERMINATE&#34;</span> <span style="color:#ff79c6">in</span> msg[<span style="color:#f1fa8c">&#34;content&#34;</span>],
</span></span><span style="display:flex;"><span>        human_input_mode<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;NEVER&#34;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Register the tool signature with the assistant agent.</span>
</span></span><span style="display:flex;"><span>    assistant<span style="color:#ff79c6">.</span>register_for_llm(
</span></span><span style="display:flex;"><span>        name<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;calculator&#34;</span>, description<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;A simple calculator&#34;</span>)(calculator)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4"># Register the tool function with the user proxy agent.</span>
</span></span><span style="display:flex;"><span>    user_proxy<span style="color:#ff79c6">.</span>register_for_execution(name<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;calculator&#34;</span>)(calculator)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    chat_result <span style="color:#ff79c6">=</span> user_proxy<span style="color:#ff79c6">.</span>initiate_chat(
</span></span><span style="display:flex;"><span>        assistant, message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;2+3等于几&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">if</span> __name__ <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><p><code>assistant.register_for_llm</code>和<code>user_proxy.register_for_execution</code>assistant和user_proxy需要同时注册tool，可以换种写法，使用<code>register_function</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> register_function
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Register the calculator function to the two agents.</span>
</span></span><span style="display:flex;"><span>register_function(
</span></span><span style="display:flex;"><span>    calculator,
</span></span><span style="display:flex;"><span>    caller<span style="color:#ff79c6">=</span>assistant,  <span style="color:#6272a4"># The assistant agent can suggest calls to the calculator.</span>
</span></span><span style="display:flex;"><span>    executor<span style="color:#ff79c6">=</span>user_proxy,  <span style="color:#6272a4"># The user proxy agent can execute the calculator calls.</span>
</span></span><span style="display:flex;"><span>    name<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;calculator&#34;</span>,  <span style="color:#6272a4"># By default, the function name is used as the tool name.</span>
</span></span><span style="display:flex;"><span>    description<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;A simple calculator&#34;</span>,  <span style="color:#6272a4"># A description of the tool.</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>如果用过OpenAI’s tool use的API，会习惯使用tool schema，下面就用tool schema方式重构下代码</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#6272a4"># 使用pydantic实现复杂的type schema</span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> pydantic <span style="color:#ff79c6">import</span> BaseModel, Field
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">class</span> <span style="color:#50fa7b">CalculatorInput</span>(BaseModel):
</span></span><span style="display:flex;"><span>    a: Annotated[<span style="color:#8be9fd;font-style:italic">int</span>, Field(description<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;The first number.&#34;</span>)]
</span></span><span style="display:flex;"><span>    b: Annotated[<span style="color:#8be9fd;font-style:italic">int</span>, Field(description<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;The second number.&#34;</span>)]
</span></span><span style="display:flex;"><span>    operator: Annotated[Operator, Field(description<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;The operator.&#34;</span>)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">calculator</span>(<span style="color:#8be9fd;font-style:italic">input</span>: Annotated[CalculatorInput, <span style="color:#f1fa8c">&#34;Input to the calculator.&#34;</span>]) <span style="color:#ff79c6">-&gt;</span> <span style="color:#8be9fd;font-style:italic">int</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>operator <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;+&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>a <span style="color:#ff79c6">+</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>b
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>operator <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;-&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>a <span style="color:#ff79c6">-</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>b
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>operator <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;*&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>a <span style="color:#ff79c6">*</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>b
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>operator <span style="color:#ff79c6">==</span> <span style="color:#f1fa8c">&#34;/&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">int</span>(<span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>a <span style="color:#ff79c6">/</span> <span style="color:#8be9fd;font-style:italic">input</span><span style="color:#ff79c6">.</span>b)
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">raise</span> ValueError(<span style="color:#f1fa8c">&#34;Invalid operator&#34;</span>)
</span></span></code></pre></div><h3 id="对话模式">对话模式</h3>
<h4 id="双agent互聊">双Agent互聊</h4>
<p>
  <img src="https://microsoft.github.io/autogen/assets/images/two-agent-chat-512f70f6b1393b05dc9019c322b15213.png" alt="two-agent-chat">

</p>
<h4 id="顺序聊">顺序聊</h4>
<p>
  <img src="https://microsoft.github.io/autogen/assets/images/sequential-two-agent-chat-804707a28b6a1aea61d4a700dc210595.png" alt="sequential-two-agent-chat">

</p>
<h4 id="群聊">群聊</h4>
<p>
  <img src="https://microsoft.github.io/autogen/assets/images/group-chat-2c88a3b4769d60898d0d4d2313d2d168.png" alt="group-chat">

</p>
<h4 id="嵌套聊">嵌套聊</h4>
<p>
  <img src="https://microsoft.github.io/autogen/assets/images/nested-chats-857c3a6a2115d53d588e4fea09d5daf7.png" alt="nested-chats">

</p>
<h2 id="应用场景">应用场景</h2>
<h2 id="第三方集成">第三方集成</h2>
<h3 id="ollama">Ollama</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> autogen <span style="color:#ff79c6">import</span> AssistantAgent, UserProxyAgent
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>config_list <span style="color:#ff79c6">=</span> [
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;model&#34;</span>: <span style="color:#f1fa8c">&#34;codellama&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;base_url&#34;</span>: <span style="color:#f1fa8c">&#34;http://localhost:11434/v1&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;api_key&#34;</span>: <span style="color:#f1fa8c">&#34;ollama&#34;</span>,
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>assistant <span style="color:#ff79c6">=</span> AssistantAgent(<span style="color:#f1fa8c">&#34;assistant&#34;</span>, llm_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;config_list&#34;</span>: config_list})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>user_proxy <span style="color:#ff79c6">=</span> UserProxyAgent(<span style="color:#f1fa8c">&#34;user_proxy&#34;</span>, code_execution_config<span style="color:#ff79c6">=</span>{<span style="color:#f1fa8c">&#34;work_dir&#34;</span>: <span style="color:#f1fa8c">&#34;coding&#34;</span>, <span style="color:#f1fa8c">&#34;use_docker&#34;</span>: <span style="color:#ff79c6">False</span>})
</span></span><span style="display:flex;"><span>user_proxy<span style="color:#ff79c6">.</span>initiate_chat(assistant, message<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Plot a chart of NVDA and TESLA stock price change YTD.&#34;</span>)
</span></span></code></pre></div><h2 id="autogen-studio安装">AutoGen Studio安装</h2>
<p>使用autogen虚拟环境</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># conda activate pyautogen</span>
</span></span></code></pre></div><p>安装autogenstudio</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># pip install autogenstudio</span>
</span></span></code></pre></div><p>启动Web UI</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># autogenstudio ui --port 8081</span>
</span></span></code></pre></div><p>打开浏览器输入<code>http://127.0.0.1:8081/</code>访问</p>
<h3 id="autogen-studio核心概念">AutoGen Studio核心概念</h3>
<p>Build:</p>
<ul>
<li>Skills: python函数，Agent用它来完成相应的任务</li>
<li>Models：Agent执行使用的模型</li>
<li>Agents：Agent定义，用于Workflow</li>
<li>Workflows：包含Agent的Workflow，用于处理任务</li>
</ul>
<h1 id="metagpt">MetaGPT</h1>
<p>MetaGPT是一个多Agent的框架</p>
<p>
  <img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aZ7X8D9srdX9Q_k3OSPrgA.png" alt="agent架构图">

</p>
<h2 id="部署-1">部署</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># 下载metagpt镜像</span>
</span></span><span style="display:flex;"><span>docker pull metagpt/metagpt:latest
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 创建配置文件</span>
</span></span><span style="display:flex;"><span>mkdir -p /opt/metagpt/<span style="color:#ff79c6">{</span>config,workspace<span style="color:#ff79c6">}</span>
</span></span><span style="display:flex;"><span>docker run --rm metagpt/metagpt:latest cat /app/metagpt/config/config2.yaml &gt; /opt/metagpt/config/config2.yaml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 编辑配置文件，这里对接的是ollama</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># vim /opt/metagpt/config/config2.yaml</span>
</span></span><span style="display:flex;"><span>llm:
</span></span><span style="display:flex;"><span>  model: <span style="color:#f1fa8c">&#34;deepseek-coder:6.7b-instruct-q6_K&#34;</span>
</span></span><span style="display:flex;"><span>  api_type: <span style="color:#f1fa8c">&#34;ollama&#34;</span>
</span></span><span style="display:flex;"><span>  base_url: <span style="color:#f1fa8c">&#34;http://xxx:11434/api&#34;</span>
</span></span><span style="display:flex;"><span>  api_key: <span style="color:#f1fa8c">&#34;1231231455&#34;</span>  <span style="color:#6272a4">#随便填，不能不填</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mermaid:
</span></span><span style="display:flex;"><span>  engine: <span style="color:#f1fa8c">&#34;nodejs&#34;</span>
</span></span><span style="display:flex;"><span>  path: <span style="color:#f1fa8c">&#34;mmdc&#34;</span>
</span></span><span style="display:flex;"><span>  puppeteer_config: <span style="color:#f1fa8c">&#34;/app/metagpt/config/puppeteer-config.json&#34;</span>
</span></span><span style="display:flex;"><span>  pyppeteer_path: <span style="color:#f1fa8c">&#34;/usr/bin/chromium&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 启动容器</span>
</span></span><span style="display:flex;"><span>docker run --name metagpt -d <span style="color:#f1fa8c">\
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"></span>    --privileged <span style="color:#f1fa8c">\
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"></span>    -v /opt/metagpt/config/config2.yaml:/app/metagpt/config/config2.yaml <span style="color:#f1fa8c">\
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"></span>    -v /opt/metagpt/workspace:/app/metagpt/workspace <span style="color:#f1fa8c">\
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c"></span>    metagpt/metagpt:latest
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 进入容器，下发指令，比如创建一个2048游戏</span>
</span></span><span style="display:flex;"><span>docker <span style="color:#8be9fd;font-style:italic">exec</span> -it metagpt /bin/bash
</span></span><span style="display:flex;"><span>$ metagpt <span style="color:#f1fa8c">&#34;Create a 2048 game&#34;</span>
</span></span></code></pre></div><p>它会按照一个开发过程的思维来拆解任务，并输出代码。生成的代码比较固化，比如让其golang写一个监控系统，生成出来的代码框架也是python风格的。</p>
<h1 id="agentgpt">AgentGPT</h1>
<p>可以认为是AutoGPT的网页版, 在线体验环境：https://agentgpt.reworkd.ai/zh，不过autogpt现在也有自己的前端页面</p>
<h1 id="crewai">crewAI</h1>
<h2 id="简介-1">简介</h2>
<p>用于编排角色扮演、自主人工智能代理的尖端框架。通过促进协作智能，CrewAI 使代理能够无缝协作，处理复杂的任务。</p>
<p>主要特性：</p>
<ul>
<li>基于角色的代理设计：定制具有特定角色、目标和工具的代理。</li>
<li>代理间自主委派：代理可以自主委派任务并相互查询，提高解决问题的效率。</li>
<li>灵活的任务管理：使用可定制的工具定义任务并将其动态分配给代理。</li>
<li>流程驱动：目前仅支持sequential任务执行和hierarchical流程，但正在开发更复杂的流程，例如共识和自治。</li>
<li>将输出保存为文件：将各个任务的输出保存为文件，以便稍后使用。</li>
<li>将输出解析为 Pydantic 或 Json：将单个任务的输出解析为 Pydantic 模型或 Json（如果需要）。</li>
<li>使用开源模型：使用开放AI或开源模型运行您的工作人员，了解有关配置代理与模型的连接的详细信息，甚至是本地运行的模型</li>
</ul>
<p>
  <img src="https://raw.githubusercontent.com/joaomdmoura/crewAI/main/docs/crewAI-mindmap.png" alt="crewAI架构图">

</p>
<h2 id="核心概念">核心概念</h2>
<ul>
<li>Agents</li>
<li>Tasks</li>
<li>Tools</li>
<li>Processes</li>
<li>Crews</li>
<li>Memory</li>
</ul>
<h2 id="部署-2">部署</h2>
<p>安装依赖包</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install crewai
</span></span><span style="display:flex;"><span>pip install crewai_tools
</span></span></code></pre></div><h2 id="实践-1">实践</h2>
<p>运行demo示例</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> crewai <span style="color:#ff79c6">import</span> Agent, Task, Crew, Process
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> crewai_tools <span style="color:#ff79c6">import</span> SerperDevTool
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>os<span style="color:#ff79c6">.</span>environ[<span style="color:#f1fa8c">&#34;OPENAI_API_BASE&#34;</span>] <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#34;http://xxx:11434/v1&#34;</span>
</span></span><span style="display:flex;"><span>os<span style="color:#ff79c6">.</span>environ[<span style="color:#f1fa8c">&#34;OPENAI_MODEL_NAME&#34;</span>] <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#34;qwen:7b&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">#os.environ[&#34;SERPER_API_KEY&#34;] = &#34;Your Key&#34; # serper.dev API key</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># You can choose to use a local model through Ollama for example. See https://docs.crewai.com/how-to/LLM-Connections/ for more information.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># os.environ[&#34;OPENAI_API_BASE&#34;] = &#39;http://localhost:11434/v1&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># os.environ[&#34;OPENAI_MODEL_NAME&#34;] =&#39;openhermes&#39;  # Adjust based on available model</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># os.environ[&#34;OPENAI_API_KEY&#34;] =&#39;sk-111111111111111111111111111111111111111111111111&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>search_tool <span style="color:#ff79c6">=</span> SerperDevTool()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Define your agents with roles and goals</span>
</span></span><span style="display:flex;"><span>researcher <span style="color:#ff79c6">=</span> Agent(
</span></span><span style="display:flex;"><span>  role<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;Senior Research Analyst&#39;</span>,
</span></span><span style="display:flex;"><span>  goal<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;Uncover cutting-edge developments in AI and data science&#39;</span>,
</span></span><span style="display:flex;"><span>  backstory<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;&#34;&#34;You work at a leading tech think tank.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">  Your expertise lies in identifying emerging trends.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">  You have a knack for dissecting complex data and presenting actionable insights.&#34;&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  verbose<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>,
</span></span><span style="display:flex;"><span>  allow_delegation<span style="color:#ff79c6">=</span><span style="color:#ff79c6">False</span>,
</span></span><span style="display:flex;"><span>  tools<span style="color:#ff79c6">=</span>[search_tool]
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4"># You can pass an optional llm attribute specifying what mode you wanna use.</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4"># It can be a local model through Ollama / LM Studio or a remote</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4"># model like OpenAI, Mistral, Antrophic or others (https://docs.crewai.com/how-to/LLM-Connections/)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4">#</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4"># import os</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4"># os.environ[&#39;OPENAI_MODEL_NAME&#39;] = &#39;gpt-3.5-turbo&#39;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4">#</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4"># OR</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4">#</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4"># from langchain_openai import ChatOpenAI</span>
</span></span><span style="display:flex;"><span>  <span style="color:#6272a4"># llm=ChatOpenAI(model_name=&#34;gpt-3.5&#34;, temperature=0.7)</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>writer <span style="color:#ff79c6">=</span> Agent(
</span></span><span style="display:flex;"><span>  role<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;Tech Content Strategist&#39;</span>,
</span></span><span style="display:flex;"><span>  goal<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;Craft compelling content on tech advancements&#39;</span>,
</span></span><span style="display:flex;"><span>  backstory<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;&#34;&#34;You are a renowned Content Strategist, known for your insightful and engaging articles.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">  You transform complex concepts into compelling narratives.&#34;&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  verbose<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>,
</span></span><span style="display:flex;"><span>  allow_delegation<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Create tasks for your agents</span>
</span></span><span style="display:flex;"><span>task1 <span style="color:#ff79c6">=</span> Task(
</span></span><span style="display:flex;"><span>  description<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;&#34;&#34;Conduct a comprehensive analysis of the latest advancements in AI in 2024.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">  Identify key trends, breakthrough technologies, and potential industry impacts.&#34;&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  expected_output<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Full analysis report in bullet points&#34;</span>,
</span></span><span style="display:flex;"><span>  agent<span style="color:#ff79c6">=</span>researcher
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>task2 <span style="color:#ff79c6">=</span> Task(
</span></span><span style="display:flex;"><span>  description<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;&#34;&#34;Using the insights provided, develop an engaging blog
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">  post that highlights the most significant AI advancements.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">  Your post should be informative yet accessible, catering to a tech-savvy audience.
</span></span></span><span style="display:flex;"><span><span style="color:#f1fa8c">  Make it sound cool, avoid complex words so it doesn&#39;t sound like AI.&#34;&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  expected_output<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;Full blog post of at least 4 paragraphs&#34;</span>,
</span></span><span style="display:flex;"><span>  agent<span style="color:#ff79c6">=</span>writer
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Instantiate your crew with a sequential process</span>
</span></span><span style="display:flex;"><span>crew <span style="color:#ff79c6">=</span> Crew(
</span></span><span style="display:flex;"><span>  agents<span style="color:#ff79c6">=</span>[researcher, writer],
</span></span><span style="display:flex;"><span>  tasks<span style="color:#ff79c6">=</span>[task1, task2],
</span></span><span style="display:flex;"><span>  verbose<span style="color:#ff79c6">=</span><span style="color:#bd93f9">2</span>, <span style="color:#6272a4"># You can set it to 1 or 2 to different logging levels</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Get your crew to work!</span>
</span></span><span style="display:flex;"><span>result <span style="color:#ff79c6">=</span> crew<span style="color:#ff79c6">.</span>kickoff()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">&#34;######################&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">print</span>(result)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># 输出内容</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">######################</span>
</span></span><span style="display:flex;"><span>In light of recent AI advancements in Natural Language Processing <span style="color:#ff79c6">(</span>NLP<span style="color:#ff79c6">)</span>, it&#39;s clear that these breakthroughs will significantly reshape the future of the field. Key aspects to note are increased accuracy, speed, and understanding across languages. These improvements will allow <span style="color:#ff79c6">for</span> more advanced applications, such as personalized chatbots, language translation tools, and even more sophisticated virtual assistants.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>The implications <span style="color:#ff79c6">for</span> businesses operating in diverse markets are enormous. Companies that can leverage these NLP advancements will have a significant competitive edge, allowing them to better connect with customers, enhance customer satisfaction, and ultimately drive growth.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>In conclusion, AI breakthroughs in NLP are <span style="color:#8be9fd;font-style:italic">set</span> to revolutionize the field and offer businesses an unprecedented advantage. By staying informed about these developments, companies can position themselves at the forefront of this transformative trend.
</span></span></code></pre></div><p>crewAI也支持对接ollama</p>
<h1 id="chatdev">ChatDev</h1>
<h2 id="简介-2">简介</h2>
<p>ChatDev 是一家虚拟软件公司，通过各种不同角色的智能体 运营，包括执行官，产品官，技术官，程序员 ，审查员，测试员，设计师 等。这些智能体形成了一个多智能体组织结构，其使命是“通过编程改变数字世界”。ChatDev内的智能体通过参加专业的功能研讨会来 协作，包括设计、编码、测试和文档编写等任务。ChatDev的主要目标是提供一个基于大型语言模型（LLM）的易于使用、高度可定制并且可扩展的框架，它是研究群体智能的理想场景。</p>
<h2 id="部署-3">部署</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># 克隆ChatDev代码仓库</span>
</span></span><span style="display:flex;"><span>git clone https://github.com/OpenBMB/ChatDev.git
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 创建python虚拟环境</span>
</span></span><span style="display:flex;"><span>conda create -n ChatDev_conda_env <span style="color:#8be9fd;font-style:italic">python</span><span style="color:#ff79c6">=</span>3.10 -y
</span></span><span style="display:flex;"><span>conda activate ChatDev_conda_env
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 安装包依赖</span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">cd</span> ChatDev
</span></span><span style="display:flex;"><span>pip3 install -r requirements.txt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 设置OpenAI Key</span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">export</span> <span style="color:#8be9fd;font-style:italic">OPENAI_API_KEY</span><span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;&lt;your_OpenAI_API_key&gt;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 构建你的软件，格式: python3 run.py --task &#34;[description_of_your_idea]&#34; --name &#34;[project_name]&#34;</span>
</span></span><span style="display:flex;"><span>python3 run.py --task <span style="color:#f1fa8c">&#34;使用golang编写一个game2048游戏&#34;</span> --name <span style="color:#f1fa8c">&#34;demo&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># 重复运行软件：项目目录第一次创建完会在WareHouse/目录下生成，项目目录格式：project_name_DefaultOrganization_timestamp</span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd;font-style:italic">cd</span> WareHouse/demo_DefaultOrganization_20240408110626/
</span></span><span style="display:flex;"><span>python3 main.go
</span></span></code></pre></div><p>生成的产物都在WareHouse/目录下，虽然产物的质量可能不是很优，但是这种多智能体协同工作的思想很先进. ChatDev不支持跟Ollama集成</p>
<h1 id="swe-agent">SWE-agent</h1>
<p>SWE-agent是一个利用大语言模型(如GPT-4、Claude等)来自动化软件工程任务的智能代理系统，对标Devin。</p>
<h1 id="业界ai-agent分享总结">业界AI Agent分享总结</h1>
<h2 id="ai-agent工作流的未来---吴恩达">AI Agent工作流的未来 - 吴恩达</h2>
<p>以下内容来自吴恩达在人工智能峰会(AI Ascent)上的一次演讲</p>
<h3 id="ai-agent工作流模式">AI Agent工作流模式</h3>
<p>目前我们使用大模型的主要方式是采用一种非代理工作流程，比如输入一个Prompt，大模型就生成一个回答。以编写一篇文章为例</p>
<p>
  <img src="https://raw.githubusercontent.com/yaoice/blog-images/main/2024-03-30-ai_agent_readnotes/20240330-ai-agent-workflow.jpg" alt="">

</p>
<p>非Agent工作流</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>一次性从头到尾编写一篇文章
</span></span></code></pre></div><p>Agent工作流</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>根据主题写一个文章的大纲 -&gt; 是否需要连接互联网检索 -&gt; 第一版初稿 -&gt; 思考哪部分内容需要修订 -&gt; 修订初稿 -&gt; 继续下一步动作...
</span></span></code></pre></div><p>相比非代理工作流，迭代多次可以带来显著的改进效果。他指出通过研究发现，GPT-3.5使用零样本进行prompt时有48%的正确率，GPT-4使用零样本进行prompt时有67%。如果基于GPT-3.5之上引入一个代理工作流，表现出来的效果比GPT-4还要好。</p>
<h3 id="ai-agent设计模式">AI Agent设计模式</h3>
<h4 id="反思模式reflection">反思模式(reflection)</h4>
<p>
  <img src="https://raw.githubusercontent.com/yaoice/blog-images/main/2024-03-30-ai_agent_readnotes/2024-03-30-ai_agent_readnotes%3A20240330-ai-agent-mode-reflection.jpg" alt="">


把之前生成好的代码再次输入给模型，并让模型检查代码问题并给出建议。模型接受反馈后会生成更好的代码版本。转化为AI Agent的话，就是有两个Agent，一个是编码Agent，另一个是评审Agent。不同的Agent以不同的是方式进行Prompt。</p>
<ul>
<li>编码Agent：你是一个资深的编码程序员，请编写代码</li>
<li>评审Agent：你是一个资深的代码review专家，请review这段代码</li>
</ul>
<h4 id="工具使用模式tool-use">工具使用模式(Tool Use)</h4>
<p>
  <img src="https://raw.githubusercontent.com/yaoice/blog-images/main/2024-03-30-ai_agent_readnotes/20240330-ai-agent-mode-tool-use.jpg" alt="">


现在的语言模型可以搜索网页、生成和运行代码等，借助工具可以扩展大语言模型的能力。</p>
<h4 id="规划模式planning">规划模式(Planning)</h4>
<p>
  <img src="https://raw.githubusercontent.com/yaoice/blog-images/main/2024-03-30-ai_agent_readnotes/2024-03-30-ai_agent_readnotes%3A20240330-ai-agent-mode-planning.jpg" alt="">


从论文中摘录一个例子：你给出一张男孩的图像，并说根据说明生成一张女孩的新图像。现在我们有了这样的人工智能代理:它可以确定第一步是确定男孩的姿势，然后可能在Hugging Face上找到一个合适的模型来提取这个姿势，接下来要找到一个姿势图像模型来合成一个女孩的图像，然后使用图像到文本的模型，最后使用语音合成。</p>
<h4 id="多智能体协作模式multi-agent-collaboration">多智能体协作模式(Multi Agent Collaboration)</h4>
<p>
  <img src="https://raw.githubusercontent.com/yaoice/blog-images/main/2024-03-30-ai_agent_readnotes/20240330-ai-agent-mode-multiagent-collaboration.jpg" alt="">


这里提到了面壁智能开源的项目ChatDev提出了一种利用AI代理协作完成复杂任务的方法。该方法使用一个语言模型扮演不同的角色，例如公司 CEO、设计师、产品经理或测试员，这些代理相互协作，协同完成一项复杂的任务。研究还发现,让不同的人工智能代理进行辩论，也能提高它们的表现。</p>
<h3 id="总结">总结</h3>
<ul>
<li>预测通过Agent工作流胜任的任务种类今年将会大幅铺开</li>
<li>在Agent工作流中，要改变过往的习惯，学会等待才能得到响应；就像交代任务给其他人，需要一段时间再来验收任务完成情况</li>
<li>快速生成token也很重要，使用质量略低但速度更快的语言模型，通过更多轮次的迭代，也可能比使用更高质量但速度较慢的模型获得更好的结果</li>
</ul>


                
                
<div class="entry-shang text-center">
    
	    <p>「真诚赞赏，手留余香」</p>
	
	<button class="zs show-zs btn btn-bred">赞赏支持</button>
</div>
<div class="zs-modal-bg"></div>
<div class="zs-modal-box">
	<div class="zs-modal-head">
		<button type="button" class="close">×</button>
		<span class="author"><a href="https://www.iceyao.com.cn/"><img src="/img/favicon.png" />爱折腾的工程师</a></span>
        
	        <p class="tip"><i></i><span>真诚赞赏，手留余香</span></p>
		
 
	</div>
	<div class="zs-modal-body">
		<div class="zs-modal-btns">
			<button class="btn btn-blink" data-num="2">2元</button>
			<button class="btn btn-blink" data-num="5">5元</button>
			<button class="btn btn-blink" data-num="10">10元</button>
			<button class="btn btn-blink" data-num="50">50元</button>
			<button class="btn btn-blink" data-num="100">100元</button>
			<button class="btn btn-blink" data-num="1">任意金额</button>
		</div>
		<div class="zs-modal-pay">
			<button class="btn btn-bred" id="pay-text">2元</button>
			<p>使用<span id="pay-type">微信</span>扫描二维码完成支付</p>
			<img src="/img/reward/wechat-2.png"  id="pay-image"/>
		</div>
	</div>
	<div class="zs-modal-footer">
		<label><input type="radio" name="zs-type" value="wechat" class="zs-type" checked="checked"><span ><span class="zs-wechat"><img src="/img/reward/wechat-btn.png"/></span></label>
		<label><input type="radio" name="zs-type" value="alipay" class="zs-type" class="zs-alipay"><img src="/img/reward/alipay-btn.png"/></span></label>
	</div>
</div>
<script type="text/javascript" src="/js/reward.js"></script>

                

                
                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2024/03/21/python-knowledge/" data-toggle="tooltip" data-placement="top" title="Python知识点大杂烩">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                </ul>
                

                


<script src="https://giscus.app/client.js"
        data-repo="yaoice/yaoice.github.io"
        data-repo-id="R_kgDOJnxqVg"
        data-category="General"
        data-category-id="DIC_kwDOJnxqVs4CWwUs"
        data-mapping="pathname"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>


            </div>

            
            
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
            

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                        
                        
                        
                        
                        
                        <a href="/tags/devops" title="devops">
                            devops
                        </a>
                        
                        
                        
                        <a href="/tags/go" title="go">
                            go
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/k8s" title="k8s">
                            k8s
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/llm" title="llm">
                            llm
                        </a>
                        
                        
                        
                        <a href="/tags/openstack" title="openstack">
                            openstack
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/tkestack" title="tkestack">
                            tkestack
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E7%BB%83%E8%BD%A6" title="练车">
                            练车
                        </a>
                        
                        
                    </div>
                </section>
                

                
                
            </div>
        </div>
    </div>
</article>









<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">                  
                    
                    <li>
                        <a href="mailto:yao3690093@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		           
                    
                    
                    
                    

		            
                    
                    <li>
                        <a target="_blank" href="/img/wechat.jpeg">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-weixin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		            
                    
                    <li>
                        <a target="_blank" href="https://github.com/yaoice">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		            
                    
                    
                    
                    
                    
                    
                    
                    
                    
            
            
            
           
                   <li>
                       <a href='' rel="alternate" type="application/rss+xml" title="爱折腾的工程师" >
                           <span class="fa-stack fa-lg">
                               <i class="fas fa-circle fa-stack-2x"></i>
                               <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
                           </span>
                       </a>
                   </li>
            
             </ul>
		<p class="copyright text-muted">
                    Copyright &copy; 爱折腾的工程师 2024
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function loadAsync(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        loadAsync("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>



<script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https'){
       bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else{
      bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>


<script>
    
    var _baId = '92c175994ded75a3cd2074bc1123e2be';

    
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>




<script type="text/javascript">
    function generateCatalog(selector) {

        
        
        
        
            _containerSelector = 'div.post-container'
        

        
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        
        $(selector).html('')

        
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    


    loadAsync("\/js\/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>







</body>
</html>
