<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="爱折腾的工程师">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://www.iceyao.com.cn/img/post-bg-unix-linux.jpg">
    <meta property="twitter:image" content="https://www.iceyao.com.cn/img/post-bg-unix-linux.jpg" />
    

    
    <meta name="title" content="TKEStack gpu-manager源码阅读笔记" />
    <meta property="og:title" content="TKEStack gpu-manager源码阅读笔记" />
    <meta property="twitter:title" content="TKEStack gpu-manager源码阅读笔记" />
    

    
    <meta name="description" content="iceyao，程序员, 开源爱好者，生活探险家 | 这里是iceyao的博客，与你一起发现更大的世界。">
    <meta property="og:description" content="iceyao，程序员, 开源爱好者，生活探险家 | 这里是iceyao的博客，与你一起发现更大的世界。" />
    <meta property="twitter:description" content="iceyao，程序员, 开源爱好者，生活探险家 | 这里是iceyao的博客，与你一起发现更大的世界。" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="iceyao, IceYao&#39;s Blog, 博客, 个人网站, 互联网, Web, 云原生, PaaS, Istio, Kubernetes, 微服务, Microservice">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>TKEStack gpu-manager源码阅读笔记 | 爱折腾的工程师 | IceYao&#39;s Blog</title>

    <link rel="canonical" href="/post/2020-11-15-gpu_manager_reading_note/">

    
    
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hugo-theme-cleanwhite.min.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">

    
    <link rel="stylesheet" href="/css/font-awesome.all.min.css">

    
    

    
    <script src="/js/jquery.min.js"></script>

    
    <script src="/js/bootstrap.min.js"></script>

    
    <script src="/js/hux-blog.min.js"></script>

    
    <script src="/js/lazysizes.min.js"></script>

    
    

</head>



<script async src="https://www.googletagmanager.com/gtag/js?id=G-9J7CKFVPPM"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-9J7CKFVPPM', { 'anonymize_ip': false });
}
</script>






<nav class="navbar navbar-default navbar-custom navbar-fixed-top">

    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">爱折腾的工程师</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">All Posts</a>
                    </li>
                    
                        
                    
                    
		    
                        <li><a href="/archive//">ARCHIVE</a></li>
                    
                        <li><a href="/notes//">NOTES</a></li>
                    
                        <li><a href="/about//">ABOUT</a></li>
                    
		            <li>
                        <a href="/search"><i class="fa fa-search"></i></a>
		           </li>
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/post-bg-unix-linux.jpg')
    }
</style>

<header class="intro-header" >

    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/tkestack" title="tkestack">
                            tkestack
                        </a>
                        
                    </div>
                    <h1>TKEStack gpu-manager源码阅读笔记</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        
                            Posted by 
                            
                                    爱折腾的工程师
                             
                            on 
                            Sunday, November 15, 2020
                            
                            
                            
                            
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                <h3 id="环境">环境</h3>
<ul>
<li>系统：CentOS 7</li>
<li>kernel: 3.10.0-862.el7.x86_64</li>
<li>Kubernetes: v1.19.3</li>
</ul>
<h3 id="gpu-manager简介">gpu-manager简介</h3>
<blockquote>
<p>GPU Manager用于管理Kubernetes集群中的nvidia GPU设备。它实现了Kubernetes的DevicePlugin接口。因此它与1.9+的Kubernetes发行版兼容.
为了与<code>nvidia-docker</code>和<code>nvidia-k8s-plugin</code>的组合解决方案进行比较，GPU管理器将使用未经修改的原生runc，
而nvidia解决方案则进行了修改。此外，我们还支持指标报告，而无需部署新组件。为了正确地调度GPU负载，GPU管理器应该使用<a href="https://github.com/tkestack/gpu-admission">gpu-admission</a>（这是kubernetes调度程序插件）.
GPU管理器还支持带有GPU设备分数资源的有效负载，例如0.1卡或100MiB gpu设备内存。如果您想要这种功能，请参考<a href="https://github.com/tkestack/vcuda-controller">vcuda-controller</a>项目。</p>
</blockquote>
<h3 id="安装nvidia显卡驱动">安装nvidia显卡驱动</h3>
<p>配置cuda源</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">wget https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda-repo-rhel7-10-0-local-10.0.130-410.48-1.0-1.x86_64
mv cuda-repo-rhel7-10-0-local-10.0.130-410.48-1.0-1.x86_64 cuda-repo-rhel7-10-0-local-10.0.130-410.48-1.0-1.x86_64.rpm
rpm -Uvh cuda-repo-rhel7-10-0-local-10.0.130-410.48-1.0-1.x86_64.rpm
yum install cuda
</code></pre></div><p>验证nvidia包是否装上</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#6272a4"># rpm -qa|grep -i nvidia</span>
nvidia-libXNVCtrl-410.48-1.el7.x86_64
nvidia-libXNVCtrl-devel-410.48-1.el7.x86_64
nvidia-driver-410.48-1.el7.x86_64
nvidia-persistenced-410.48-1.el7.x86_64
nvidia-driver-cuda-libs-410.48-1.el7.x86_64
nvidia-xconfig-410.48-1.el7.x86_64
nvidia-modprobe-410.48-1.el7.x86_64
nvidia-settings-410.48-1.el7.x86_64
nvidia-driver-NvFBCOpenGL-410.48-1.el7.x86_64
nvidia-driver-NVML-410.48-1.el7.x86_64
nvidia-driver-devel-410.48-1.el7.x86_64
dkms-nvidia-410.48-1.el7.x86_64
nvidia-driver-cuda-410.48-1.el7.x86_64
nvidia-driver-libs-410.48-1.el7.x86_64
</code></pre></div><p>重启系统，使用命令查看GPU显卡信息</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#6272a4"># nvidia-container-cli -k info</span>
NVRM version:   410.48
CUDA version:   10.0

Device Index:   <span style="color:#bd93f9">0</span>
Device Minor:   <span style="color:#bd93f9">0</span>
Model:          Tesla P40
Brand:          Tesla
GPU UUID:       GPU-750f713a-e058-8803-7ed5-4810b457ed96
Bus Location:   00000000:04:00.0
Architecture:   6.1
...

</code></pre></div><h3 id="gpu-manager部署">gpu-manager部署</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">git clone https://github.com/tkestack/gpu-manager.git
</code></pre></div><p>最新的tag是v1.1.0，dockerhub上没有对应编译好的image</p>
<p>编译镜像</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">make img
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#6272a4"># 给有显卡的node节点打label</span>
kubectl label &lt;node-x&gt; 9.19.177.194 nvidia-device-enable<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">enable</span>
</code></pre></div><p>gpu-manager部署yaml</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gpu-manager
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: gpu-manager
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: gpu-manager
  namespace: kube-system
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: gpu-manager-daemonset
  namespace: kube-system
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      name: gpu-manager-ds
  template:
    metadata:
      <span style="color:#6272a4"># This annotation is deprecated. Kept here for backward compatibility</span>
      <span style="color:#6272a4"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span>
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: <span style="color:#f1fa8c">&#34;&#34;</span>
      labels:
        name: gpu-manager-ds
    spec:
      serviceAccount: gpu-manager
      tolerations:
        <span style="color:#6272a4"># This toleration is deprecated. Kept here for backward compatibility</span>
        <span style="color:#6272a4"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span>
        - key: CriticalAddonsOnly
          operator: Exists
        - key: tencent.com/vcuda-core
          operator: Exists
          effect: NoSchedule
      <span style="color:#6272a4"># Mark this pod as a critical add-on; when enabled, the critical add-on</span>
      <span style="color:#6272a4"># scheduler reserves resources for critical add-on pods so that they can</span>
      <span style="color:#6272a4"># be rescheduled after a failure.</span>
      <span style="color:#6272a4"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span>
      priorityClassName: <span style="color:#f1fa8c">&#34;system-node-critical&#34;</span>
      <span style="color:#6272a4"># only run node hash gpu device</span>
      nodeSelector:
        nvidia-device-enable: <span style="color:#8be9fd;font-style:italic">enable</span>
      hostPID: <span style="color:#8be9fd;font-style:italic">true</span>
      containers:
        - image: tkestack/gpu-manager:1.1.0
          imagePullPolicy: IfNotPresent
          name: gpu-manager
          securityContext:
            privileged: <span style="color:#8be9fd;font-style:italic">true</span>
          ports:
            - containerPort: <span style="color:#bd93f9">5678</span>
          volumeMounts:
            - name: device-plugin
              mountPath: /var/lib/kubelet/device-plugins
            - name: vdriver
              mountPath: /etc/gpu-manager/vdriver
            - name: vmdata
              mountPath: /etc/gpu-manager/vm
            - name: log
              mountPath: /var/log/gpu-manager
            - name: run-dir
              mountPath: /var/run
            - name: cgroup
              mountPath: /sys/fs/cgroup
              readOnly: <span style="color:#8be9fd;font-style:italic">true</span>
            - name: usr-directory
              mountPath: /usr/local/host
              readOnly: <span style="color:#8be9fd;font-style:italic">true</span>
          env:
            - name: LOG_LEVEL
              value: <span style="color:#f1fa8c">&#34;5&#34;</span>
            - name: EXTRA_FLAGS
              value: <span style="color:#f1fa8c">&#34;--logtostderr=true&#34;</span>
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
      volumes:
        - name: device-plugin
          hostPath:
            type: Directory
            path: /var/lib/kubelet/device-plugins
        - name: vmdata
          hostPath:
            type: DirectoryOrCreate
            path: /etc/gpu-manager/vm
        - name: vdriver
          hostPath:
            type: DirectoryOrCreate
            path: /etc/gpu-manager/vdriver
        - name: log
          hostPath:
            type: DirectoryOrCreate
            path: /etc/gpu-manager/log
        <span style="color:#6272a4"># We have to mount the whole /var/run directory into container, because of bind mount docker.sock</span>
        <span style="color:#6272a4"># inode change after host docker is restarted</span>
        - name: run-dir
          hostPath:
            type: Directory
            path: /var/run
        - name: cgroup
          hostPath:
            type: Directory
            path: /sys/fs/cgroup
        <span style="color:#6272a4"># We have to mount /usr directory instead of specified library path, because of non-existing</span>
        <span style="color:#6272a4"># problem for different distro</span>
        - name: usr-directory
          hostPath:
            type: Directory
            path: /usr
---
apiVersion: v1
kind: Service
metadata:
  name: gpu-manager-metric
  namespace: kube-system
  annotations:
    prometheus.io/scrape: <span style="color:#f1fa8c">&#34;true&#34;</span>
  labels:
    kubernetes.io/cluster-service: <span style="color:#f1fa8c">&#34;true&#34;</span>
spec:
  clusterIP: None
  ports:
    - name: metrics
      port: <span style="color:#bd93f9">5678</span>
      protocol: TCP
      targetPort: <span style="color:#bd93f9">5678</span>
  selector:
    name: gpu-manager-ds
</code></pre></div><h3 id="gpu-admission部署">gpu-admission部署</h3>
<p>创建gpu-quota-admission配置文件</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#8be9fd;font-style:italic">echo</span> <span style="color:#f1fa8c">&#39;
</span><span style="color:#f1fa8c">{
</span><span style="color:#f1fa8c">	&#34;QuotaConfigMapName&#34;: &#34;gpuquota&#34;,
</span><span style="color:#f1fa8c">	&#34;QuotaConfigMapNamespace&#34;: &#34;kube-system&#34;,
</span><span style="color:#f1fa8c">	&#34;GPUModelLabel&#34;: &#34;gaia.tencent.com/gpu-model&#34;,
</span><span style="color:#f1fa8c">	&#34;GPUPoolLabel&#34;: &#34;gaia.tencent.com/gpu-pool&#34;
</span><span style="color:#f1fa8c">}&#39;</span> &gt; /etc/kubernetes/gpu-quota-admission.config
</code></pre></div><p>static pod方式部署gpu-quota-admission</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">mkdir -p /etc/kubernetes/kube-scheduler/
cp /root/.kube/config /etc/kubernetes/kube-scheduler/kubeconfig

<span style="color:#8be9fd;font-style:italic">echo</span> <span style="color:#f1fa8c">&#39;
</span><span style="color:#f1fa8c">apiVersion: v1
</span><span style="color:#f1fa8c">kind: Pod
</span><span style="color:#f1fa8c">metadata:
</span><span style="color:#f1fa8c">  annotations:
</span><span style="color:#f1fa8c">    scheduler.alpha.kubernetes.io/critical-pod: &#34;&#34;
</span><span style="color:#f1fa8c">  name: gpu-admission
</span><span style="color:#f1fa8c">  namespace: kube-system
</span><span style="color:#f1fa8c">spec:
</span><span style="color:#f1fa8c">  containers:
</span><span style="color:#f1fa8c">  - image: tkestack/gpu-quota-admission:v1.0.0 
</span><span style="color:#f1fa8c">    imagePullPolicy: IfNotPresent 
</span><span style="color:#f1fa8c">    name: gpu-admission
</span><span style="color:#f1fa8c">    env:
</span><span style="color:#f1fa8c">    - name: LOG_LEVEL
</span><span style="color:#f1fa8c">      value: &#34;4&#34;
</span><span style="color:#f1fa8c">    - name: EXTRA_FLAGS
</span><span style="color:#f1fa8c">      value: &#34;--incluster-mode=false&#34;
</span><span style="color:#f1fa8c">    ports:
</span><span style="color:#f1fa8c">    - containerPort: 3456
</span><span style="color:#f1fa8c">    volumeMounts:
</span><span style="color:#f1fa8c">    - mountPath: /etc/kubernetes/
</span><span style="color:#f1fa8c">      name: kubernetes
</span><span style="color:#f1fa8c">      readOnly: true
</span><span style="color:#f1fa8c">    - mountPath: /var/log/gpu-admission
</span><span style="color:#f1fa8c">      name: log
</span><span style="color:#f1fa8c">  dnsPolicy: ClusterFirstWithHostNet
</span><span style="color:#f1fa8c">  hostNetwork: true
</span><span style="color:#f1fa8c">  priority: 2000000000
</span><span style="color:#f1fa8c">  priorityClassName: system-cluster-critical
</span><span style="color:#f1fa8c">  volumes:
</span><span style="color:#f1fa8c">  - hostPath:
</span><span style="color:#f1fa8c">      type: Directory
</span><span style="color:#f1fa8c">      path: /etc/kubernetes/
</span><span style="color:#f1fa8c">    name: kubernetes
</span><span style="color:#f1fa8c">  - hostPath:
</span><span style="color:#f1fa8c">      type: DirectoryOrCreate
</span><span style="color:#f1fa8c">      path: /var/log/gpu-admission
</span><span style="color:#f1fa8c">    name: log
</span><span style="color:#f1fa8c">&#39;</span> &gt; /etc/kubernetes/manifests/gpu-admission.yaml
</code></pre></div><p>配置kube-scheduler调度策略</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#8be9fd;font-style:italic">echo</span> <span style="color:#f1fa8c">&#39;
</span><span style="color:#f1fa8c">{
</span><span style="color:#f1fa8c">    &#34;kind&#34;: &#34;Policy&#34;,
</span><span style="color:#f1fa8c">    &#34;apiVersion&#34;: &#34;v1&#34;,
</span><span style="color:#f1fa8c">    &#34;predicates&#34;: [
</span><span style="color:#f1fa8c">        {
</span><span style="color:#f1fa8c">            &#34;name&#34;: &#34;PodFitsHostPorts&#34;
</span><span style="color:#f1fa8c">        },
</span><span style="color:#f1fa8c">        {
</span><span style="color:#f1fa8c">            &#34;name&#34;: &#34;PodFitsResources&#34;
</span><span style="color:#f1fa8c">        },
</span><span style="color:#f1fa8c">        {
</span><span style="color:#f1fa8c">            &#34;name&#34;: &#34;NoDiskConflict&#34;
</span><span style="color:#f1fa8c">        },
</span><span style="color:#f1fa8c">        {
</span><span style="color:#f1fa8c">            &#34;name&#34;: &#34;MatchNodeSelector&#34;
</span><span style="color:#f1fa8c">        },
</span><span style="color:#f1fa8c">        {
</span><span style="color:#f1fa8c">            &#34;name&#34;: &#34;HostName&#34;
</span><span style="color:#f1fa8c">        }
</span><span style="color:#f1fa8c">    ],
</span><span style="color:#f1fa8c">    &#34;priorities&#34;: [
</span><span style="color:#f1fa8c">        {
</span><span style="color:#f1fa8c">            &#34;name&#34;: &#34;BalancedResourceAllocation&#34;,
</span><span style="color:#f1fa8c">            &#34;weight&#34;: 1
</span><span style="color:#f1fa8c">        },
</span><span style="color:#f1fa8c">        {
</span><span style="color:#f1fa8c">            &#34;name&#34;: &#34;ServiceSpreadingPriority&#34;,
</span><span style="color:#f1fa8c">            &#34;weight&#34;: 1
</span><span style="color:#f1fa8c">        }
</span><span style="color:#f1fa8c">    ],
</span><span style="color:#f1fa8c">    &#34;extenders&#34;: [
</span><span style="color:#f1fa8c">        {
</span><span style="color:#f1fa8c">            &#34;urlPrefix&#34;: &#34;http://127.0.0.1:3456/scheduler&#34;,
</span><span style="color:#f1fa8c">            &#34;apiVersion&#34;: &#34;v1beta1&#34;,
</span><span style="color:#f1fa8c">            &#34;filterVerb&#34;: &#34;predicates&#34;,
</span><span style="color:#f1fa8c">            &#34;enableHttps&#34;: false,
</span><span style="color:#f1fa8c">            &#34;nodeCacheCapable&#34;: false
</span><span style="color:#f1fa8c">        }
</span><span style="color:#f1fa8c">    ],
</span><span style="color:#f1fa8c">    &#34;hardPodAffinitySymmetricWeight&#34;: 10,
</span><span style="color:#f1fa8c">    &#34;alwaysCheckAllPredicates&#34;: false
</span><span style="color:#f1fa8c">}&#39;</span> &gt; /etc/kubernetes/scheduler-policy-config.json
</code></pre></div><p>让上述调度策略文件生效，重启kube-scheduler服务</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">vim /etc/kubernetes/manifests/kube-scheduler.yaml
    - --policy-config-file<span style="color:#ff79c6">=</span>/etc/kubernetes/scheduler-policy-config.json
    - --use-legacy-policy-config<span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">true</span>
</code></pre></div><h3 id="验证测试">验证测试</h3>
<h4 id="查看节点显卡资源">查看节点显卡资源</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl  describe nodes node53
......
tencent.com/vcuda-core:    700<span style="color:#ff79c6">(</span>7张GPU卡<span style="color:#ff79c6">)</span>
 tencent.com/vcuda-memory:  668<span style="color:#ff79c6">(</span>总共256M*668M显存<span style="color:#ff79c6">)</span>
</code></pre></div><p>可以看到可分配的显卡资源</p>
<h4 id="整卡分配">整卡分配</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#ff79c6">[</span>root@node53 ~<span style="color:#ff79c6">]</span><span style="color:#6272a4"># cat test.yaml </span>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vcuda-test
spec:
  selector:
    matchLabels:
      app: vcuda-test
  template:
    metadata:
      labels:
        app: vcuda-test
    spec:
      containers:
      - name: vcuda-test
        image: nvidia/cuda:10.1-base-centos7
        command: <span style="color:#ff79c6">[</span><span style="color:#f1fa8c">&#39;/usr/local/nvidia/bin/nvidia-smi&#39;</span>, <span style="color:#f1fa8c">&#39;-l&#39;</span>, <span style="color:#f1fa8c">&#39;1&#39;</span><span style="color:#ff79c6">]</span>
        resources:
          requests:
            tencent.com/vcuda-core: <span style="color:#bd93f9">100</span>
            tencent.com/vcuda-memory: <span style="color:#bd93f9">30</span>
          limits:
            tencent.com/vcuda-core: <span style="color:#bd93f9">100</span>
            tencent.com/vcuda-memory: <span style="color:#bd93f9">30</span>
</code></pre></div><h3 id="非整卡分配">非整卡分配</h3>
<h3 id="gpu-manager代码分析">gpu-manager代码分析</h3>
<h4 id="接口">接口</h4>
<p>Manager接口</p>
<pre tabindex="0"><code>//Manager api
type Manager interface {
	Ready() bool
	Run() error
	RegisterToKubelet() error
}
</code></pre><p>ResourceServer接口</p>
<pre tabindex="0"><code>//ResourceServer api for manager
type ResourceServer interface {
	Run() error
	Stop()
	SocketName() string
	ResourceName() string
}
</code></pre><p>GPUTopoService接口</p>
<pre tabindex="0"><code>//GPUTopoService is server api for GPU topology service
type GPUTopoService interface {
	pluginapi.DevicePluginServer
	ListAndWatchWithResourceName(string, *pluginapi.Empty, pluginapi.DevicePlugin_ListAndWatchServer) error
}
</code></pre><p>GPUTree接口</p>
<pre tabindex="0"><code>//GPUTree is an interface for GPU tree structure
type GPUTree interface {
	Init(input string)
	Update()
}
</code></pre><h4 id="结构体">结构体</h4>
<p>Options结构体</p>
<pre tabindex="0"><code>// Options contains plugin information
type Options struct {
    //GPU manager驱动，默认值为nvidia
	Driver                   string
    //额外配置文件加载路径
	ExtraPath                string
    //volume配置文件路径，volume.conf记录了具体路径关于使用到的cuda命令和nvidia cuda库
	VolumeConfigPath         string
    //让prometheus查询metric监听的端口
	QueryPort                int
    //让prometheus查询metric监听的地址
	QueryAddr                string
    //kubeConfig路径，获取集群资源信息的凭证 
	KubeConfigFile           string
    //每张GPU卡执行的时间段，默认单位秒
	SamplePeriod             int
    //节点自动打标签
	NodeLabels               string
    //节点主机名标识，非实际主机名
	HostnameOverride         string
    //virtual manager配置文件路径，默认值为/etc/gpu-manager/vm
	VirtualManagerPath       string
    //device plugin注册插件的路径
	DevicePluginPath         string
    //是否启用GPU共享分配
	EnableShare              bool
    //检查已分配GPU的间隔，单位秒 
	AllocationCheckPeriod    int
    //checkpoint配置存储的路径，默认值为/etc/gpu-manager
	CheckpointPath           string
    //容器运行时，默认值为/var/run/dockershim.sock
	ContainerRuntimeEndpoint string
    //cgroup驱动，默认cgroupfs，还有systemd
	CgroupDriver             string
    //请求容器运行时的超时时间
	RequestTimeout           time.Duration
}
</code></pre><p>Config结构体, 定义的变量跟Options结构体类似</p>
<pre tabindex="0"><code>// Config contains the necessary options for the plugin.
type Config struct {
	Driver                   string
	ExtraConfigPath          string
	QueryPort                int
	QueryAddr                string
	KubeConfig               string
	SamplePeriod             time.Duration
	Hostname                 string
	NodeLabels               map[string]string
	VirtualManagerPath       string
	DevicePluginPath         string
	VolumeConfigPath         string
	EnableShare              bool
	AllocationCheckPeriod    time.Duration
	CheckpointPath           string
	ContainerRuntimeEndpoint string
	CgroupDriver             string
	RequestTimeout           time.Duration
    // 存放cuda请求的channel
	VCudaRequestsQueue chan *types.VCudaRequest
}
</code></pre><p>managerImpl结构体，实现了Manager接口</p>
<pre tabindex="0"><code>type managerImpl struct {
	config *config.Config
    //提供GPU拓扑服务的API
	allocator      allocFactory.GPUTopoService
    //显示GPU资源使用情况
	displayer      *display.Display
    //管理GPU资源
	virtualManager *vitrual_manager.VirtualManager
    //管理vcore和vmemory资源
	bundleServer map[string]ResourceServer
    //grpc server，接收gprc请求
	srv          *grpc.Server
}
</code></pre><p>Display结构体</p>
<pre tabindex="0"><code>//Display is used to show GPU device usage
type Display struct {
	sync.Mutex

	config                  *config.Config
    //nvidia GPU资源树
	tree                    *nvtree.NvidiaTree
    //容器运行时manager
	containerRuntimeManager runtime.ContainerRuntimeInterface
}
</code></pre><p>VolumeManager结构体</p>
<pre tabindex="0"><code>//VolumeManager manages volumes used by containers running GPU application
type VolumeManager struct {
	Config  []Config `json:&quot;volume,omitempty&quot;`
	cfgPath string

	cudaControlFile string
	cudaSoname      map[string]string
	mlSoName        map[string]string
	share           bool
}
</code></pre><p>containerRuntimeManager结构体, 实现了ContainerRuntimeInterface接口</p>
<pre tabindex="0"><code>type containerRuntimeManager struct {
	cgroupDriver   string
	runtimeName    string
	requestTimeout time.Duration
	client         criapi.RuntimeServiceClient
}
</code></pre><p>nodeLabeler结构体</p>
<pre tabindex="0"><code>type nodeLabeler struct {
	hostName    string
	client      v1core.CoreV1Interface
	labelMapper map[string]labelFunc
}
</code></pre><p>NvidiaTree结构体</p>
<pre tabindex="0"><code>//NvidiaTree represents a Nvidia GPU in a tree.
type NvidiaTree struct {
	sync.Mutex

	root   *NvidiaNode
	leaves []*NvidiaNode

	realMode     bool
	query        map[string]*NvidiaNode
	index        int
	samplePeriod time.Duration
}
</code></pre><h4 id="启动函数">启动函数</h4>
<pre tabindex="0"><code># tkestack.io/gpu-manager/cmd/manager/nvidia-manager.go
func main() {
	klog.InitFlags(nil)
	opt := options.NewOptions()
	opt.AddFlags(pflag.CommandLine)

	flags.InitFlags()
	goflag.CommandLine.Parse([]string{})
	logs.InitLogs()
	defer logs.FlushLogs()

	version.PrintAndExitIfRequested()

	if err := app.Run(opt); err != nil {
		fmt.Fprintf(os.Stderr, &quot;%v\n&quot;, err)
		os.Exit(1)
	}
}
</code></pre><p>app.Run主要执行逻辑：</p>
<ol>
<li>解析Options对象(配置参数)，来填充Config对象</li>
<li>初始化managerImpl对象(实现了Manager接口)，执行接口中定义的Run函数
<ul>
<li>校验config.ExtraConfigPath</li>
<li>判断config.Driver是否为空</li>
<li>如果配置了config.VolumeConfigPath，就初始化VolumeManager对象，执行VolumeManager.Run函数(解析volume.conf,创建对应的目录/硬链接,拷贝对应的文件)</li>
<li>systemd发送<code>READY=1</code>notify信息给daemon</li>
<li>初始化ContainerRuntimeManager对象, 和容器运行时交互</li>
<li>初始化clientSet, 使用sharedInformer创建pod cache(当前主机的所有pod)</li>
<li>初始化nodeLabeler对象, 快速更新节点label</li>
<li>初始化VirtualManager对象，执行VirtualManager的Run函数
<ul>
<li>判断VirtualManagerPath是否为空，创建VirtualManagerPath目录</li>
<li>执行vDeviceWatcher，遍历使用vgpu的running pod, 在<code>/etc/gpu-manager/vm/</code>每个pod目录对应一个vDevice的grpc server，并放入<code>DeviceServers map数据结构</code>
每隔1min循环检测pod目录，如果不存在即停止grpc server，从<code>DeviceServers map数据结构</code>删除对应key</li>
<li>执行garbageCollector，进行pod垃圾目录回收; 遍历<code>/etc/gpu-manager/vm/</code>目录下的pod目录，从所有使用vgpu的running pod中查找，不存在即删除对应的pod目录</li>
<li>执行process，遍历VCudaRequestsQueue channel，获取对应事件记录的podUID，再次执行这个过程：
在<code>/etc/gpu-manager/vm/</code>每个pod目录对应一个vDevice的grpc server，并放入<code>DeviceServers map数据结构</code></li>
</ul>
</li>
</ul>
</li>
<li>从deviceFactory设备工厂函数中根据config.Driver类型返回一个有名函数<code>NewFunc func(cfg *config.Config) GPUTree</code>，用于获取实现了<code>GPUTree</code>接口的具体实例对象；
<ul>
<li>
<p>实现了GPUTree接口的有两类结构体：NvidiaTree和DummyTree，这两类结构体在其init函数实现了设备主册，顾名思义起作用的只有NvidiaTree.</p>
</li>
<li>
<p>执行了<code>GPUTree</code>接口的Init和Update函数(gpu拓扑结构感知)
Init函数：</p>
<pre tabindex="0"><code>//Init a NvidiaTree.
//Will try to use nvml first, fallback to input string if
//parseFromLibrary() failed.
func (t *NvidiaTree) Init(input string) {
	err := t.parseFromLibrary()
	if err == nil {
      t.realMode = true
      return
	}

	klog.V(2).Infof(&quot;Can't use nvidia library, err %s. Use text parser&quot;, err)
  //此处不会调用到，即使调用到也立即返回错误
	err = t.parseFromString(input)

	if err != nil {
      klog.Fatalf(&quot;Can not initialize nvidia tree, err %s&quot;, err)
	}
}
</code></pre><p>//封装了github.com/tkestack/go-nvml库，简化调用nvml的操作</p>
<pre tabindex="0"><code>func (t *NvidiaTree) parseFromLibrary() error {
  //Initialize NVML, but don't initialize any GPUs yet
	if err := nvml.Init(); err != nil {
      return err
	}
  //Shut down NVML by releasing all GPU resources previously allocated with nvmlInit_v2()
	defer nvml.Shutdown()
  //Retrieves the version of the system's graphics driver.
	driverVersion, err := nvml.SystemGetDriverVersion()
	if err != nil {
      return err
	}
  //Retrieves the number of compute devices in the system. A compute device is a single GPU.
	num, err := nvml.DeviceGetCount()
	if err != nil {
      return err
	}

	klog.V(2).Infof(&quot;Detect %d gpu cards&quot;, num)

	nodes := make(LevelMap)
	t.leaves = make([]*NvidiaNode, num)

	for i := 0; i &lt; int(num); i++ {
      //Acquire the handle for a particular device, based on its index.
      dev, _ := nvml.DeviceGetHandleByIndex(uint(i))
      //Retrieves the amount of used, free and total memory available on the device, in bytes.
      _, _, totalMem, _ := dev.DeviceGetMemoryInfo()
      //Retrieves the PCI attributes of this device.
      pciInfo, _ := dev.DeviceGetPciInfo()
      //Retrieves minor number for the device. 
      //The minor number for the device is such that the Nvidia device node file for each GPU will have the form /dev/nvidia[minor number].
      minorID, _ := dev.DeviceGetMinorNumber()
      //Retrieves the NVML index of this device.
      uuid, _ := dev.DeviceGetUUID()
      //初始化新NvidiaNode对象
      n := t.allocateNode(i)
      n.AllocatableMeta.Cores = HundredCore
      n.AllocatableMeta.Memory = int64(totalMem)
      n.Meta.TotalMemory = totalMem
      n.Meta.BusId = pciInfo.BusID
      n.Meta.MinorID = int(minorID)
      n.Meta.UUID = uuid
      //填充query map数据结构和leaves slice数组
      t.addNode(n)
	}

	for cardA := uint(0); cardA &lt; num; cardA++ {
      //Acquire the handle for a particular device, based on its index.
      devA, _ := nvml.DeviceGetHandleByIndex(cardA)
      for cardB := cardA + 1; cardB &lt; num; cardB++ {
          devB, _ := nvml.DeviceGetHandleByIndex(cardB)
          //Retrieve the common ancestor for two devices For all products. Supported on Linux only.
          ntype, err := nvml.DeviceGetTopologyCommonAncestor(devA, devB)
          if err != nil {
              return err
          }

          switch driverVersion {
          case &quot;396.26&quot;:
              if ntype == nvml.TOPOLOGY_INTERNAL {
                  ntype = nvml.TOPOLOGY_SINGLE
              }
          default:
          }
          if newNode := t.join(nodes, ntype, int(cardA), int(cardB)); newNode != nil {
              klog.V(2).Infof(&quot;New node, type %d, mask %b&quot;, int(ntype), newNode.Mask)
              nodes[ntype] = append(nodes[ntype], newNode)
          }
      }
	}

	for t, ns := range nodes {
      klog.V(2).Infof(&quot;type: %d, len %d&quot;, int(t), len(ns))
	}

	t.buildTree(nodes)

	return nil
}
</code></pre><p>Update函数</p>
<pre tabindex="0"><code>//Update NvidiaTree by info getting from GPU devices.
//Return immediately if real GPU device is not available.
func (t *NvidiaTree) Update() {
   if !t.realMode {
      return
   }
    //Initialize NVML, but don't initialize any GPUs yet
    if err := nvml.Init(); err != nil {
        return
    }

    defer nvml.Shutdown()

    klog.V(4).Infof(&quot;Update device information&quot;)

    t.Lock()
    defer t.Unlock()

    for i := range t.Leaves() {
        node := t.updateNode(i)

        if node.pendingReset &amp;&amp; node.AllocatableMeta.Cores == HundredCore {
            resetGPUFeature(node, t.realMode)

            if !node.pendingReset {
                t.freeNode(node)
            }
        }

        klog.V(4).Infof(&quot;node %d, pid: %+v, memory: %+v, utilization: %+v, pendingReset: %+v&quot;,
            i, node.Meta.Pids, node.Meta.UsedMemory, node.Meta.Utilization, node.pendingReset)

        node = node.Parent
        for node != nil {
            node.Meta.Pids = make([]uint, 0)
            node.Meta.UsedMemory = 0
            node.Meta.TotalMemory = 0

            for _, child := range node.Children {
                node.Meta.Pids = append(node.Meta.Pids, child.Meta.Pids...)
                node.Meta.UsedMemory += child.Meta.UsedMemory
                node.Meta.TotalMemory += child.Meta.TotalMemory
            }

            node = node.Parent
        }
    }
}
</code></pre><p>更新树节点显存使用情况，还有pid列表</p>
</li>
</ul>
</li>
</ol>
<p>GPU拓扑结构矩阵图</p>
<pre tabindex="0"><code># nvidia-smi topo -m
	    GPU0	GPU1	GPU2	GPU3	GPU4	GPU5	GPU6	mlx4_0	CPU Affinity	NUMA Affinity
GPU0	 X 	    PIX	    PIX	    PHB	    PHB	    PHB	    PHB	    PIX	    0-13,28-41	    0
GPU1	PIX	    X 	    PIX	    PHB	    PHB	    PHB	    PHB	    PIX	    0-13,28-41	    0
GPU2	PIX	    PIX	    X 	    PHB	    PHB	    PHB	    PHB	    PIX	    0-13,28-41	    0
GPU3	PHB	    PHB	    PHB	    X 	    PIX	    PIX	    PIX	    PHB	    0-13,28-41	    0 
GPU4	PHB	    PHB	    PHB	    PIX	    X 	    PIX	    PIX	    PHB	    0-13,28-41	    0
GPU5	PHB	    PHB	    PHB	    PIX	    PIX	    X 	    PIX	    PHB	    0-13,28-41	    0
GPU6	PHB	    PHB	    PHB	    PIX	    PIX	    PIX	    X 	    PHB	    0-13,28-41	    0
mlx4_0	PIX	    PIX	    PIX	    PHB	    PHB	    PHB	    PHB	 X 		

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks 
</code></pre><p>理想状态下构建出来的树状结构是:</p>
<pre tabindex="0"><code>ROOT:7:0
|--PHB:7:0
|  |--PIX:3:0
|  |  |--GPU0:1:1
|  |  |--GPU1:1:1
|  |  |--GPU2:1:1
|  |--PIX:4:0
|  |  |--GPU3:1:2
|  |  |--GPU4:1:2
|  |  |--GPU5:1:2
|  |  |--GPU6:1:2
</code></pre><p>资源-访问代价树</p>
<blockquote>
<p>拓扑节点中存储3个信息：
• 子节点的GPU通信方式(SOC、PXB、PHB或
PIX)
• 可用的GPU资源数(如果下属n张GPU卡则为n)
• 节点通信开销(非GPU节点为0)
GPU节点存储3个信息：
• GPU id
• 可用的GPU资源数(GPU节点为1)
• 节点通信开销(数字越小，访问代价越低)</p>
</blockquote>
<p>六类通信方式分类中，通信开销：
NV# &lt; PIX &lt; PXB &lt; PHB &lt; NODE &lt; SYS</p>
<p>根据代码得出的树状图跟理论模型有差异</p>
<pre tabindex="0"><code>ROOT:7:0
|--PHB:7:0
|  |--PHB:3:0
|  |  |--GPU0:1:1
|  |  |--GPU1:1:1
|  |  |--GPU2:1:1
|  |--PIX:4:0
|  |  |--GPU3:1:2
|  |  |--GPU4:1:2
|  |  |--GPU5:1:2
|  |  |--GPU6:1:2
</code></pre><ol start="4">
<li>
<p>从allocFactory工厂函数中根据config.Driver类型返回一个有名函数<code>NewFunc func(cfg *config.Config, tree device.GPUTree, k8sClient kubernetes.Interface) GPUTopoService</code>，
用于获取实现了<code>GPUTopoService</code>接口的具体实例对象；这里config.Driver是nvidia,所以返回的是NvidiaTopoAllocator对象</p>
<pre tabindex="0"><code>//Register stores NewFunc in factory
func Register(name string, item NewFunc) {
    if _, ok := factory[name]; ok {
        return
    }

    klog.V(2).Infof(&quot;Register NewFunc with name %s&quot;, name)

    factory[name] = item
}

//NewFuncForName tries to find NewFunc by name, return nil if not found
func NewFuncForName(name string) NewFunc {
    if item, ok := factory[name]; ok {
        return item
    }

    klog.V(2).Infof(&quot;Can not find NewFunc with name %s&quot;, name)

    return nil
}
</code></pre><p>NvidiaTopoAllocator调用Register函数实现插件注册</p>
<pre tabindex="0"><code>func init() {
    allocator.Register(&quot;nvidia&quot;, NewNvidiaTopoAllocator)
    allocator.Register(&quot;nvidia_test&quot;, NewNvidiaTopoAllocatorForTest)
}

//NewNvidiaTopoAllocator returns a new NvidiaTopoAllocator
func NewNvidiaTopoAllocator(config *config.Config, tree device.GPUTree, k8sClient kubernetes.Interface) allocator.GPUTopoService {
    _tree, _ := tree.(*nvtree.NvidiaTree)
    cm, err := checkpoint.NewManager(config.CheckpointPath, checkpointFileName)
    if err != nil {
        klog.Fatalf(&quot;Failed to create checkpoint manager due to %s&quot;, err.Error())
    }
    alloc := &amp;NvidiaTopoAllocator{
        tree:              _tree,
        config:            config,
        evaluators:        make(map[string]Evaluator),
        allocatedPod:      cache.NewAllocateCache(),
        k8sClient:         k8sClient,
        queue:             workqueue.NewRateLimitingQueue(workqueue.DefaultControllerRateLimiter()),
        stopChan:          make(chan struct{}),
        checkpointManager: cm,
    }

    // Load kernel module if it's not loaded
    //加载nvidia-uvm nvidia内核模块
    alloc.loadModule()

    // Initialize evaluator
    //映射到三种不同模式(link、fragment、share)的树结构
    alloc.initEvaluator(_tree)

    // Read extra config if it's given
    alloc.loadExtraConfig(config.ExtraConfigPath)

    // Process allocation results in another goroutine
    //标准controller的process函数，不断从队列中获取key，根据结果给pod patch上annotation
    go wait.Until(alloc.runProcessResult, time.Second, alloc.stopChan)

    // Recover
    //故障恢复的处理函数
    alloc.recoverInUsed()

    // Check allocation in another goroutine periodically
    //定时器检测gpu pod的卡分配，类似垃圾回收器
    go alloc.checkAllocationPeriodically(alloc.stopChan)

    return alloc
}
</code></pre></li>
<li>
<p>初始化返回一个Display对象，记录GPU卡的使用情况</p>
</li>
<li>
<p>启动vcore和vmemory grpc server，两种device plugin插件的具体实现</p>
</li>
<li>
<p>建立/pprof的api调用</p>
</li>
<li>
<p>建立/metric的api调用，暴露metric值; 监听在http地址和端口</p>
</li>
<li>
<p>监听unix socket，启动服务</p>
</li>
</ol>
<h3 id="gpu-admission代码分析">gpu-admission代码分析</h3>
<h3 id="参考链接">参考链接</h3>
<ul>
<li><a href="https://www.itread01.com/content/1543303098.html">CentOS7.5的GPU 1080 Ti 顯示卡安裝cuda</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/53421721">腾讯企业容器云平台技术解析</a></li>
</ul>


                
                
<div class="entry-shang text-center">
    
	    <p>「真诚赞赏，手留余香」</p>
	
	<button class="zs show-zs btn btn-bred">赞赏支持</button>
</div>
<div class="zs-modal-bg"></div>
<div class="zs-modal-box">
	<div class="zs-modal-head">
		<button type="button" class="close">×</button>
		<span class="author"><a href="https://www.iceyao.com.cn"><img src="/img/favicon.png" />爱折腾的工程师</a></span>
        
	        <p class="tip"><i></i><span>真诚赞赏，手留余香</span></p>
		
 
	</div>
	<div class="zs-modal-body">
		<div class="zs-modal-btns">
			<button class="btn btn-blink" data-num="2">2元</button>
			<button class="btn btn-blink" data-num="5">5元</button>
			<button class="btn btn-blink" data-num="10">10元</button>
			<button class="btn btn-blink" data-num="50">50元</button>
			<button class="btn btn-blink" data-num="100">100元</button>
			<button class="btn btn-blink" data-num="1">任意金额</button>
		</div>
		<div class="zs-modal-pay">
			<button class="btn btn-bred" id="pay-text">2元</button>
			<p>使用<span id="pay-type">微信</span>扫描二维码完成支付</p>
			<img src="/img/reward/wechat-2.png"  id="pay-image"/>
		</div>
	</div>
	<div class="zs-modal-footer">
		<label><input type="radio" name="zs-type" value="wechat" class="zs-type" checked="checked"><span ><span class="zs-wechat"><img src="/img/reward/wechat-btn.png"/></span></label>
		<label><input type="radio" name="zs-type" value="alipay" class="zs-type" class="zs-alipay"><img src="/img/reward/alipay-btn.png"/></span></label>
	</div>
</div>
<script type="text/javascript" src="/js/reward.js"></script>

                

                
                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/post/2020-11-11-device_plugin_learning_note/" data-toggle="tooltip" data-placement="top" title="K8S device plugin学习笔记">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/post/2020-11-28-k8s_dual_stack/" data-toggle="tooltip" data-placement="top" title="k8s ipv4/ipv6双栈实践">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>
                

                


<script src="https://giscus.app/client.js"
        data-repo="yaoice/yaoice.github.io"
        data-repo-id="R_kgDOJnxqVg"
        data-category="General"
        data-category-id="DIC_kwDOJnxqVs4CWwUs"
        data-mapping="pathname"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>


            </div>

            
            
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
            

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                        
                        
                        
                        
                        
                        <a href="/tags/devops" title="devops">
                            devops
                        </a>
                        
                        
                        
                        <a href="/tags/go" title="go">
                            go
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/k8s" title="k8s">
                            k8s
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/llm" title="llm">
                            llm
                        </a>
                        
                        
                        
                        <a href="/tags/openstack" title="openstack">
                            openstack
                        </a>
                        
                        
                        
                        
                        
                        <a href="/tags/tkestack" title="tkestack">
                            tkestack
                        </a>
                        
                        
                        
                        
                        
                        
                        
                        <a href="/tags/%E7%BB%83%E8%BD%A6" title="练车">
                            练车
                        </a>
                        
                        
                    </div>
                </section>
                

                
                
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">                  
                    
                    <li>
                        <a href="mailto:yao3690093@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		           
                    
                    
                    
                    

		            
                    
                    <li>
                        <a target="_blank" href="/img/wechat.jpeg">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-weixin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		            
                    
                    <li>
                        <a target="_blank" href="https://github.com/yaoice">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		            
                    
                    
                    
                    
                    
                    
                    
                    
                    
            
            
            
           
                   <li>
                       <a href='' rel="alternate" type="application/rss+xml" title="爱折腾的工程师" >
                           <span class="fa-stack fa-lg">
                               <i class="fas fa-circle fa-stack-2x"></i>
                               <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
                           </span>
                       </a>
                   </li>
            
             </ul>
		<p class="copyright text-muted">
                    Copyright &copy; 爱折腾的工程师 2024
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function loadAsync(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        loadAsync("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>



<script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https'){
       bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else{
      bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>


<script>
    
    var _baId = '92c175994ded75a3cd2074bc1123e2be';

    
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>




<script type="text/javascript">
    function generateCatalog(selector) {

        
        
        
        
            _containerSelector = 'div.post-container'
        

        
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        
        $(selector).html('')

        
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    


    loadAsync("\/js\/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>






</body>
</html>
